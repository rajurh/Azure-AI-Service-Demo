{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3518c6f",
   "metadata": {},
   "source": [
    "# Azure AI Speech Services Demo\n",
    "\n",
    "This notebook demonstrates the capabilities of Azure AI Speech Services including:\n",
    "- **Text-to-Speech (TTS)**: Convert text to natural-sounding speech\n",
    "- **Speech-to-Text (STT)**: Convert spoken audio to text\n",
    "- **Speech Translation**: Real-time speech translation\n",
    "- **Voice Recognition**: Identify and verify speakers\n",
    "- **Custom Speech Models**: Train models for specific domains\n",
    "\n",
    "## Prerequisites\n",
    "- Azure subscription\n",
    "- Azure Speech resource created in Azure portal\n",
    "- Python 3.8 or higher\n",
    "- Audio input/output capabilities (microphone and speakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f9cdc",
   "metadata": {},
   "source": [
    "## 1. Setup and Package Installation\n",
    "\n",
    "First, let's install the required Azure Speech SDK and supporting packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d0d6cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-speech in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (1.34.1)\n",
      "Requirement already satisfied: azure-identity in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (1.15.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: requests in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: matplotlib in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from azure-identity) (1.29.5)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from azure-identity) (45.0.4)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.24.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from azure-identity) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity) (4.14.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.24.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: pycparser in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: librosa in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: IPython in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (9.3.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from soundfile) (2.2.6)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (4.14.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from IPython) (0.4.6)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from IPython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from IPython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from IPython) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from IPython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from IPython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from IPython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from IPython) (5.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from jedi>=0.16->IPython) (0.8.4)\n",
      "Requirement already satisfied: packaging in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.4)\n",
      "Requirement already satisfied: wcwidth in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from stack_data->IPython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from stack_data->IPython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from stack_data->IPython) (0.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\raju\\training\\aoai\\azureaidemos\\azure_ai_env\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required Azure Speech SDK and supporting packages\n",
    "!pip install azure-cognitiveservices-speech azure-identity python-dotenv requests matplotlib numpy\n",
    "\n",
    "# For audio processing and visualization\n",
    "!pip install soundfile librosa IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc635c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Azure Speech SDK version: 1.34.1\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Setup output directory\n",
    "output_dir = Path('output/speech')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Azure Speech SDK version: {speechsdk.__version__}\")\n",
    "print(f\"Output directory: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260c36b",
   "metadata": {},
   "source": [
    "## 2. Azure Speech Service Configuration\n",
    "\n",
    "### Option 1: Using Environment Variables (Recommended)\n",
    "Set these environment variables in your system or create a `.env` file:\n",
    "```\n",
    "AZURE_SPEECH_KEY=your-speech-api-key\n",
    "AZURE_SPEECH_REGION=your-region  # e.g., eastus, westus2\n",
    "```\n",
    "\n",
    "### Option 2: Using Managed Identity (For Azure-hosted applications)\n",
    "When running on Azure services with managed identity enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e88c9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Speech service configured for region: eastus\n",
      "🎤 Default recognition language: en-US\n",
      "🗣️ Default synthesis voice: en-US-AriaNeural\n"
     ]
    }
   ],
   "source": [
    "# Configuration for Azure Speech Service\n",
    "speech_key = os.getenv('AZURE_SPEECH_KEY') or \"your-speech-key-here\"\n",
    "speech_region = os.getenv('AZURE_SPEECH_REGION') or \"eastus\"\n",
    "\n",
    "# Create speech configuration\n",
    "if speech_key and speech_key != \"your-speech-key-here\":\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    print(f\"✅ Speech service configured for region: {speech_region}\")\n",
    "else:\n",
    "    print(\"❌ Please set AZURE_SPEECH_KEY and AZURE_SPEECH_REGION environment variables\")\n",
    "    print(\"You can get these from your Azure Speech resource in the Azure portal\")\n",
    "\n",
    "# Set default voice and language settings\n",
    "speech_config.speech_synthesis_voice_name = \"en-US-AriaNeural\"  # Default voice\n",
    "speech_config.speech_recognition_language = \"en-US\"  # Default language\n",
    "\n",
    "print(f\"🎤 Default recognition language: {speech_config.speech_recognition_language}\")\n",
    "print(f\"🗣️ Default synthesis voice: {speech_config.speech_synthesis_voice_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f81909",
   "metadata": {},
   "source": [
    "## 3. Text-to-Speech (TTS)\n",
    "\n",
    "Text-to-Speech converts written text into natural-sounding spoken audio. Azure offers:\n",
    "- **100+ voices** in multiple languages\n",
    "- **Neural voices** with human-like quality\n",
    "- **SSML support** for fine-tuning speech\n",
    "- **Custom voices** for brand-specific needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Hello! Welcome to Azure AI Speech Services. This is a demonstration of text-to-speech capabilities using neural voices.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_speech(text, voice_name=None, output_file=None):\n",
    "    \"\"\"\n",
    "    Convert text to speech using Azure Speech Service\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to convert to speech\n",
    "        voice_name (str): Optional voice name (e.g., 'en-US-AriaNeural')\n",
    "        output_file (str): Optional file name to save audio (will be saved in output/speech/)\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to saved file if successful, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if speech_config is available\n",
    "        if 'speech_config' not in globals():\n",
    "            print(\"❌ Speech configuration not available. Please run the configuration cell first.\")\n",
    "            return None\n",
    "            \n",
    "        # Create a copy of speech config for this request\n",
    "        current_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "        \n",
    "        if voice_name:\n",
    "            current_config.speech_synthesis_voice_name = voice_name\n",
    "        else:\n",
    "            current_config.speech_synthesis_voice_name = speech_config.speech_synthesis_voice_name\n",
    "        \n",
    "        # Configure audio output\n",
    "        if output_file:\n",
    "            # Ensure file is saved in output/speech directory\n",
    "            output_path = output_dir / output_file\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(filename=str(output_path))\n",
    "        else:\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "        \n",
    "        # Create synthesizer\n",
    "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=current_config, audio_config=audio_config)\n",
    "        \n",
    "        print(f\"🎵 Converting text to speech...\")\n",
    "        print(f\"📝 Text: '{text}'\")\n",
    "        print(f\"🗣️ Voice: {current_config.speech_synthesis_voice_name}\")\n",
    "        \n",
    "        # Perform synthesis\n",
    "        result = synthesizer.speak_text_async(text).get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(f\"✅ Speech synthesis completed successfully!\")\n",
    "            if output_file:\n",
    "                print(f\"💾 Audio saved to: {output_path}\")\n",
    "                # Display audio player in notebook\n",
    "                display(Audio(str(output_path)))\n",
    "                return str(output_path)\n",
    "            return \"Success (played on speakers)\"\n",
    "        elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "            cancellation = result.cancellation_details\n",
    "            print(f\"❌ Speech synthesis canceled: {cancellation.reason}\")\n",
    "            if cancellation.reason == speechsdk.CancellationReason.Error:\n",
    "                print(f\"Error details: {cancellation.error_details}\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in text-to-speech: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test basic text-to-speech\n",
    "test_text = \"Hello! Welcome to Azure AI Speech Services. This is a demonstration of text-to-speech capabilities using neural voices.\"\n",
    "\n",
    "# Convert to speech and save to file\n",
    "output_file = \"sample_speech.wav\"\n",
    "result_path = text_to_speech(test_text, output_file=output_file)\n",
    "if result_path:\n",
    "    print(f\"\\n🎉 Test completed! Audio file available at: {result_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d81ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎭 Demonstrating different voices:\n",
      "\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Hi there! I'm Aria, a neural voice from the United States.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🗣️ Voice: en-GB-SoniaNeural\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Hello! I'm Sonia, speaking with a British accent.'\n",
      "🗣️ Voice: en-GB-SoniaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🗣️ Voice: en-GB-SoniaNeural\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Hello! I'm Sonia, speaking with a British accent.'\n",
      "🗣️ Voice: en-GB-SoniaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🗣️ Voice: en-AU-NatashaNeural\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'G'day! I'm Natasha from Australia.'\n",
      "🗣️ Voice: en-AU-NatashaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🗣️ Voice: en-AU-NatashaNeural\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'G'day! I'm Natasha from Australia.'\n",
      "🗣️ Voice: en-AU-NatashaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🗣️ Voice: fr-FR-DeniseNeural\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Bonjour! Je suis Denise et je parle français.'\n",
      "🗣️ Voice: fr-FR-DeniseNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🗣️ Voice: fr-FR-DeniseNeural\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Bonjour! Je suis Denise et je parle français.'\n",
      "🗣️ Voice: fr-FR-DeniseNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🗣️ Voice: de-DE-KatjaNeural\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Hallo! Ich bin Katja und spreche Deutsch.'\n",
      "🗣️ Voice: de-DE-KatjaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🗣️ Voice: de-DE-KatjaNeural\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Hallo! Ich bin Katja und spreche Deutsch.'\n",
      "🗣️ Voice: de-DE-KatjaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate different voices\n",
    "voices_to_try = [\n",
    "    (\"en-US-AriaNeural\", \"Hi there! I'm Aria, a neural voice from the United States.\"),\n",
    "    (\"en-GB-SoniaNeural\", \"Hello! I'm Sonia, speaking with a British accent.\"),\n",
    "    (\"en-AU-NatashaNeural\", \"G'day! I'm Natasha from Australia.\"),\n",
    "    (\"fr-FR-DeniseNeural\", \"Bonjour! Je suis Denise et je parle français.\"),\n",
    "    (\"de-DE-KatjaNeural\", \"Hallo! Ich bin Katja und spreche Deutsch.\")\n",
    "]\n",
    "\n",
    "print(\"🎭 Demonstrating different voices:\")\n",
    "voice_files = []\n",
    "\n",
    "for voice, text in voices_to_try:\n",
    "    print(f\"\\n🗣️ Voice: {voice}\")\n",
    "    # Create safer filename\n",
    "    safe_voice_name = voice.replace('-', '_').replace('Neural', '')\n",
    "    output_file = f\"voice_demo_{safe_voice_name}.wav\"\n",
    "    \n",
    "    result_path = text_to_speech(text, voice_name=voice, output_file=output_file)\n",
    "    if result_path:\n",
    "        voice_files.append(result_path)\n",
    "        time.sleep(1)  # Brief pause between voices\n",
    "\n",
    "print(f\"\\n✅ Voice demonstration completed! Generated {len(voice_files)} audio files in {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3be983",
   "metadata": {},
   "source": [
    "### Advanced Text-to-Speech with SSML\n",
    "\n",
    "**Speech Synthesis Markup Language (SSML)** allows fine-tuning of speech output:\n",
    "- Adjust speaking rate, pitch, and volume\n",
    "- Add pauses and emphasis\n",
    "- Control pronunciation\n",
    "- Insert audio effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c0237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎭 SSML Example: Rate and Pitch\n",
      "🎵 Converting SSML to speech...\n",
      "📝 SSML: \n",
      "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
      "        <voi...\n",
      "❌ SSML synthesis failed: ResultReason.Canceled\n",
      "❌ SSML synthesis failed: ResultReason.Canceled\n",
      "\n",
      "🎭 SSML Example: Emphasis and Pauses\n",
      "🎵 Converting SSML to speech...\n",
      "📝 SSML: \n",
      "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
      "        <voi...\n",
      "\n",
      "🎭 SSML Example: Emphasis and Pauses\n",
      "🎵 Converting SSML to speech...\n",
      "📝 SSML: \n",
      "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
      "        <voi...\n",
      "❌ SSML synthesis failed: ResultReason.Canceled\n",
      "❌ SSML synthesis failed: ResultReason.Canceled\n",
      "\n",
      "🎭 SSML Example: Multiple Voices\n",
      "🎵 Converting SSML to speech...\n",
      "📝 SSML: \n",
      "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
      "        <voi...\n",
      "\n",
      "🎭 SSML Example: Multiple Voices\n",
      "🎵 Converting SSML to speech...\n",
      "📝 SSML: \n",
      "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
      "        <voi...\n",
      "❌ SSML synthesis failed: ResultReason.Canceled\n",
      "❌ SSML synthesis failed: ResultReason.Canceled\n"
     ]
    }
   ],
   "source": [
    "def ssml_to_speech(ssml_text, output_file=None):\n",
    "    \"\"\"\n",
    "    Convert SSML text to speech\n",
    "    \n",
    "    Args:\n",
    "        ssml_text (str): SSML formatted text\n",
    "        output_file (str): Optional file name to save audio (will be saved in output/speech/)\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to saved file if successful, None otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if speech_config is available\n",
    "        if 'speech_config' not in globals():\n",
    "            print(\"❌ Speech configuration not available. Please run the configuration cell first.\")\n",
    "            return None\n",
    "            \n",
    "        # Configure audio output\n",
    "        if output_file:\n",
    "            output_path = output_dir / output_file\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(filename=str(output_path))\n",
    "        else:\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "        \n",
    "        # Create synthesizer\n",
    "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "        \n",
    "        print(f\"🎵 Converting SSML to speech...\")\n",
    "        print(f\"📝 SSML: {ssml_text[:100]}...\" if len(ssml_text) > 100 else f\"📝 SSML: {ssml_text}\")\n",
    "        \n",
    "        # Perform synthesis\n",
    "        result = synthesizer.speak_ssml_async(ssml_text).get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(f\"✅ SSML synthesis completed successfully!\")\n",
    "            if output_file:\n",
    "                print(f\"💾 Audio saved to: {output_path}\")\n",
    "                display(Audio(str(output_path)))\n",
    "                return str(output_path)\n",
    "            return \"Success (played on speakers)\"\n",
    "        else:\n",
    "            print(f\"❌ SSML synthesis failed: {result.reason}\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in SSML synthesis: {e}\")\n",
    "        return None\n",
    "\n",
    "# SSML examples demonstrating various features\n",
    "ssml_examples = {\n",
    "    \"Rate_and_Pitch\": '''\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
    "        <voice name=\"en-US-AriaNeural\">\n",
    "            <prosody rate=\"slow\" pitch=\"low\">This is slow and low.</prosody>\n",
    "            <break time=\"1s\"/>\n",
    "            <prosody rate=\"fast\" pitch=\"high\">This is fast and high!</prosody>\n",
    "        </voice>\n",
    "    </speak>\n",
    "    ''',\n",
    "    \n",
    "    \"Emphasis_and_Pauses\": '''\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
    "        <voice name=\"en-US-AriaNeural\">\n",
    "            This is <emphasis level=\"strong\">very important</emphasis>.\n",
    "            <break time=\"2s\"/>\n",
    "            Let me repeat that again... <break time=\"1s\"/>\n",
    "            This is <emphasis level=\"strong\">very important</emphasis>!\n",
    "        </voice>\n",
    "    </speak>\n",
    "    ''',\n",
    "    \n",
    "    \"Multiple_Voices\": '''\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
    "        <voice name=\"en-US-AriaNeural\">\n",
    "            Hi, I'm Aria.\n",
    "        </voice>\n",
    "        <voice name=\"en-US-DavisNeural\">\n",
    "            And I'm Davis. Nice to meet you!\n",
    "        </voice>\n",
    "    </speak>\n",
    "    '''\n",
    "}\n",
    "\n",
    "# Demonstrate SSML examples\n",
    "ssml_files = []\n",
    "for name, ssml in ssml_examples.items():\n",
    "    print(f\"\\n🎭 SSML Example: {name.replace('_', ' ')}\")\n",
    "    output_file = f\"ssml_demo_{name.lower()}.wav\"\n",
    "    result_path = ssml_to_speech(ssml, output_file=output_file)\n",
    "    if result_path:\n",
    "        ssml_files.append(result_path)\n",
    "        time.sleep(1)\n",
    "\n",
    "print(f\"\\n✅ SSML demonstration completed! Generated {len(ssml_files)} audio files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2892c4eb",
   "metadata": {},
   "source": [
    "## 4. Speech-to-Text (STT)\n",
    "\n",
    "Speech-to-Text converts spoken audio into written text. Features include:\n",
    "- **Real-time transcription** from microphone or audio files\n",
    "- **Batch transcription** for large audio files\n",
    "- **Custom models** for domain-specific vocabulary\n",
    "- **Multiple language support** with automatic detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eb43dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡 To test microphone input, uncomment the line above and run the cell\n"
     ]
    }
   ],
   "source": [
    "def speech_to_text_from_microphone(duration_seconds=10):\n",
    "    \"\"\"\n",
    "    Convert speech from microphone to text\n",
    "    \n",
    "    Args:\n",
    "        duration_seconds (int): How long to listen (0 for continuous until silence)\n",
    "    \n",
    "    Returns:\n",
    "        str: Recognized text or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create recognizer with microphone\n",
    "        audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "        \n",
    "        print(f\"🎤 Listening for speech (for {duration_seconds} seconds)...\")\n",
    "        print(\"📢 Please speak now!\")\n",
    "        \n",
    "        # Start recognition\n",
    "        result = speech_recognizer.recognize_once_async().get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            print(f\"✅ Recognized: '{result.text}'\")\n",
    "            return result.text\n",
    "        elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"❌ No speech could be recognized\")\n",
    "        elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "            cancellation = result.cancellation_details\n",
    "            print(f\"❌ Speech recognition canceled: {cancellation.reason}\")\n",
    "            if cancellation.reason == speechsdk.CancellationReason.Error:\n",
    "                print(f\"Error details: {cancellation.error_details}\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in speech recognition: {e}\")\n",
    "        return None\n",
    "\n",
    "# Note: Uncomment the line below to test microphone input\n",
    "# recognized_text = speech_to_text_from_microphone()\n",
    "print(\"💡 To test microphone input, uncomment the line above and run the cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7015ab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Testing Speech-to-Text with generated audio...\n",
      "❌ Error processing audio file: Exception with error code: \n",
      "[CALL STACK BEGIN]\n",
      "\n",
      "    > pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - recognizer_create_speech_recognizer_from_config\n",
      "    - recognizer_create_speech_recognizer_from_config\n",
      "\n",
      "[CALL STACK END]\n",
      "\n",
      "Exception with an error code: 0x9 (SPXERR_UNEXPECTED_EOF)\n",
      "❌ Error processing audio file: Exception with error code: \n",
      "[CALL STACK BEGIN]\n",
      "\n",
      "    > pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - recognizer_create_speech_recognizer_from_config\n",
      "    - recognizer_create_speech_recognizer_from_config\n",
      "\n",
      "[CALL STACK END]\n",
      "\n",
      "Exception with an error code: 0x9 (SPXERR_UNEXPECTED_EOF)\n"
     ]
    }
   ],
   "source": [
    "def speech_to_text_from_file(audio_file_path):\n",
    "    \"\"\"\n",
    "    Convert speech from audio file to text\n",
    "    \n",
    "    Args:\n",
    "        audio_file_path (str): Path to audio file (can be relative or absolute)\n",
    "    \n",
    "    Returns:\n",
    "        str: Recognized text or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if speech_config is available\n",
    "        if 'speech_config' not in globals():\n",
    "            print(\"❌ Speech configuration not available. Please run the configuration cell first.\")\n",
    "            return None\n",
    "            \n",
    "        # Handle both absolute and relative paths\n",
    "        audio_path = Path(audio_file_path)\n",
    "        if not audio_path.is_absolute():\n",
    "            # Try in output/speech directory first\n",
    "            test_path = output_dir / audio_file_path\n",
    "            if test_path.exists():\n",
    "                audio_path = test_path\n",
    "            elif not audio_path.exists():\n",
    "                print(f\"❌ Audio file not found: {audio_file_path}\")\n",
    "                print(f\"   Searched in: {audio_path.absolute()} and {test_path.absolute()}\")\n",
    "                return None\n",
    "        \n",
    "        if not audio_path.exists():\n",
    "            print(f\"❌ Audio file not found: {audio_path.absolute()}\")\n",
    "            return None\n",
    "        \n",
    "        # Create recognizer with audio file\n",
    "        audio_config = speechsdk.audio.AudioConfig(filename=str(audio_path))\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "        \n",
    "        print(f\"🎵 Processing audio file: {audio_path.name}\")\n",
    "        \n",
    "        # Start recognition\n",
    "        result = speech_recognizer.recognize_once_async().get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            print(f\"✅ Recognized: '{result.text}'\")\n",
    "            return result.text\n",
    "        elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"❌ No speech could be recognized in the audio file\")\n",
    "        elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "            cancellation = result.cancellation_details\n",
    "            print(f\"❌ Speech recognition canceled: {cancellation.reason}\")\n",
    "            if cancellation.reason == speechsdk.CancellationReason.Error:\n",
    "                print(f\"Error details: {cancellation.error_details}\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing audio file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test speech-to-text with previously generated audio file\n",
    "sample_file = \"sample_speech.wav\"\n",
    "if (output_dir / sample_file).exists():\n",
    "    print(\"\\n🔄 Testing Speech-to-Text with generated audio...\")\n",
    "    recognized_text = speech_to_text_from_file(sample_file)\n",
    "    if recognized_text:\n",
    "        print(f\"📝 Original text: '{test_text}'\")\n",
    "        print(f\"🎯 Recognized text: '{recognized_text}'\")\n",
    "        \n",
    "        # Calculate similarity\n",
    "        original_words = test_text.lower().split()\n",
    "        recognized_words = recognized_text.lower().split()\n",
    "        common_words = set(original_words) & set(recognized_words)\n",
    "        similarity = len(common_words) / max(len(original_words), len(recognized_words)) * 100\n",
    "        print(f\"📊 Similarity: {similarity:.1f}%\")\n",
    "else:\n",
    "    print(\"\\n💡 No audio file found. Run the TTS examples first to generate sample audio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e2f9e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡 To test continuous recognition, uncomment the code above and run the cell\n"
     ]
    }
   ],
   "source": [
    "def continuous_speech_recognition(duration_seconds=30):\n",
    "    \"\"\"\n",
    "    Perform continuous speech recognition\n",
    "    \n",
    "    Args:\n",
    "        duration_seconds (int): How long to listen\n",
    "    \n",
    "    Returns:\n",
    "        list: List of recognized text segments\n",
    "    \"\"\"\n",
    "    try:\n",
    "        recognized_texts = []\n",
    "        \n",
    "        # Create recognizer\n",
    "        audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "        \n",
    "        # Event handlers\n",
    "        def recognized_handler(evt):\n",
    "            if evt.result.text:\n",
    "                print(f\"🎯 Recognized: {evt.result.text}\")\n",
    "                recognized_texts.append(evt.result.text)\n",
    "        \n",
    "        def recognizing_handler(evt):\n",
    "            if evt.result.text:\n",
    "                print(f\"⏳ Recognizing: {evt.result.text}\")\n",
    "        \n",
    "        # Connect event handlers\n",
    "        speech_recognizer.recognized.connect(recognized_handler)\n",
    "        speech_recognizer.recognizing.connect(recognizing_handler)\n",
    "        \n",
    "        print(f\"🎤 Starting continuous recognition for {duration_seconds} seconds...\")\n",
    "        print(\"📢 Speak multiple sentences!\")\n",
    "        \n",
    "        # Start continuous recognition\n",
    "        speech_recognizer.start_continuous_recognition()\n",
    "        \n",
    "        # Wait for the specified duration\n",
    "        time.sleep(duration_seconds)\n",
    "        \n",
    "        # Stop recognition\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        \n",
    "        print(f\"\\n✅ Continuous recognition completed!\")\n",
    "        print(f\"📊 Total segments recognized: {len(recognized_texts)}\")\n",
    "        \n",
    "        return recognized_texts\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in continuous recognition: {e}\")\n",
    "        return []\n",
    "\n",
    "# Note: Uncomment to test continuous recognition\n",
    "# print(\"\\n🔄 Testing Continuous Speech Recognition...\")\n",
    "# segments = continuous_speech_recognition(15)  # Listen for 15 seconds\n",
    "# if segments:\n",
    "#     print(\"\\n📝 All recognized segments:\")\n",
    "#     for i, segment in enumerate(segments, 1):\n",
    "#         print(f\"   {i}. {segment}\")\n",
    "\n",
    "print(\"💡 To test continuous recognition, uncomment the code above and run the cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed5d738",
   "metadata": {},
   "source": [
    "## 5. Speech Translation\n",
    "\n",
    "Speech Translation provides real-time translation of spoken language. Features:\n",
    "- **30+ source languages** supported\n",
    "- **100+ target languages** for translation\n",
    "- **Real-time translation** from speech to text or speech\n",
    "- **Multi-target translation** to multiple languages simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922daa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡 To test speech translation, uncomment the code above\n",
      "🎵 Or test with generated speech files:\n",
      "\n",
      "🎭 Testing with en-US: 'Hello, my name is John and I love technology.'\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Hello, my name is John and I love technology.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🎭 Testing with es-ES: 'Hola, me llamo Juan y me encanta la tecnología.'\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Hola, me llamo Juan y me encanta la tecnología.'\n",
      "🗣️ Voice: es-ES-ElviraNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🎭 Testing with es-ES: 'Hola, me llamo Juan y me encanta la tecnología.'\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Hola, me llamo Juan y me encanta la tecnología.'\n",
      "🗣️ Voice: es-ES-ElviraNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🎭 Testing with fr-FR: 'Bonjour, je m'appelle Jean et j'adore la technologie.'\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Bonjour, je m'appelle Jean et j'adore la technologie.'\n",
      "🗣️ Voice: fr-FR-DeniseNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "\n",
      "🎭 Testing with fr-FR: 'Bonjour, je m'appelle Jean et j'adore la technologie.'\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Bonjour, je m'appelle Jean et j'adore la technologie.'\n",
      "🗣️ Voice: fr-FR-DeniseNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n"
     ]
    }
   ],
   "source": [
    "def speech_translation_demo(source_language=\"en-US\", target_languages=[\"es\", \"fr\", \"de\"]):\n",
    "    \"\"\"\n",
    "    Demonstrate speech translation capabilities\n",
    "    \n",
    "    Args:\n",
    "        source_language (str): Source language code (e.g., 'en-US')\n",
    "        target_languages (list): List of target language codes (e.g., ['es', 'fr'])\n",
    "    \n",
    "    Returns:\n",
    "        dict: Translation results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if speech configuration is available\n",
    "        if 'speech_key' not in globals() or not speech_key:\n",
    "            print(\"❌ Speech configuration not available. Please run the configuration cell first.\")\n",
    "            return None\n",
    "            \n",
    "        # Create translation config\n",
    "        translation_config = speechsdk.translation.SpeechTranslationConfig(\n",
    "            subscription=speech_key, \n",
    "            region=speech_region\n",
    "        )\n",
    "        \n",
    "        # Set source language\n",
    "        translation_config.speech_recognition_language = source_language\n",
    "        \n",
    "        # Add target languages\n",
    "        for target_lang in target_languages:\n",
    "            translation_config.add_target_language(target_lang)\n",
    "        \n",
    "        # Create recognizer\n",
    "        audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "        translation_recognizer = speechsdk.translation.TranslationRecognizer(\n",
    "            translation_config=translation_config, \n",
    "            audio_config=audio_config\n",
    "        )\n",
    "        \n",
    "        print(f\"🌐 Speech Translation Setup:\")\n",
    "        print(f\"   🎤 Source Language: {source_language}\")\n",
    "        print(f\"   🌍 Target Languages: {', '.join(target_languages)}\")\n",
    "        print(f\"\\n📢 Please speak in {source_language}...\")\n",
    "        \n",
    "        # Perform translation\n",
    "        result = translation_recognizer.recognize_once_async().get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.TranslatedSpeech:\n",
    "            print(f\"\\n✅ Translation completed!\")\n",
    "            print(f\"🎯 Original ({source_language}): '{result.text}'\")\n",
    "            \n",
    "            translation_results = {\n",
    "                'original': result.text,\n",
    "                'translations': {}\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n🌐 Translations:\")\n",
    "            for target_lang in target_languages:\n",
    "                if target_lang in result.translations:\n",
    "                    translated_text = result.translations[target_lang]\n",
    "                    print(f\"   📍 {target_lang}: '{translated_text}'\")\n",
    "                    translation_results['translations'][target_lang] = translated_text\n",
    "            \n",
    "            return translation_results\n",
    "            \n",
    "        elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"❌ No speech could be recognized for translation\")\n",
    "        elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "            cancellation = result.cancellation_details\n",
    "            print(f\"❌ Translation canceled: {cancellation.reason}\")\n",
    "            if cancellation.reason == speechsdk.CancellationReason.Error:\n",
    "                print(f\"Error details: {cancellation.error_details}\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in speech translation: {e}\")\n",
    "        return None\n",
    "\n",
    "# Demo with text-to-speech for testing translation\n",
    "def test_translation_with_generated_speech():\n",
    "    \"\"\"\n",
    "    Test translation using generated speech\n",
    "    \"\"\"\n",
    "    # Generate test audio in different languages\n",
    "    test_phrases = {\n",
    "        \"en-US\": \"Hello, my name is John and I love technology.\",\n",
    "        \"es-ES\": \"Hola, me llamo Juan y me encanta la tecnología.\",\n",
    "        \"fr-FR\": \"Bonjour, je m'appelle Jean et j'adore la technologie.\"\n",
    "    }\n",
    "    \n",
    "    for lang, phrase in test_phrases.items():\n",
    "        print(f\"\\n🎭 Testing with {lang}: '{phrase}'\")\n",
    "        \n",
    "        # Generate speech\n",
    "        voice_mapping = {\n",
    "            \"en-US\": \"en-US-AriaNeural\",\n",
    "            \"es-ES\": \"es-ES-ElviraNeural\", \n",
    "            \"fr-FR\": \"fr-FR-DeniseNeural\"\n",
    "        }\n",
    "        \n",
    "        audio_file = f\"test_{lang.lower().replace('-', '_')}.wav\"\n",
    "        result_path = text_to_speech(phrase, voice_name=voice_mapping[lang], output_file=audio_file)\n",
    "        if result_path:\n",
    "            # Test speech-to-text recognition\n",
    "            recognized = speech_to_text_from_file(audio_file)\n",
    "            if recognized:\n",
    "                print(f\"✅ Recognition successful: '{recognized}'\")\n",
    "\n",
    "# Note: Uncomment to test speech translation\n",
    "# print(\"\\n🌐 Testing Speech Translation...\")\n",
    "# translation_result = speech_translation_demo()\n",
    "\n",
    "print(\"💡 To test speech translation, uncomment the code above\")\n",
    "print(\"🎵 Testing with generated speech files:\")\n",
    "test_translation_with_generated_speech()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db5a42",
   "metadata": {},
   "source": [
    "## 6. Available Voices and Languages\n",
    "\n",
    "Let's explore the available voices and languages in Azure Speech Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36f6c422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎭 Fetching available voices...\n",
      "❌ Failed to retrieve voices: ResultReason.Canceled\n",
      "❌ Failed to retrieve voices: ResultReason.Canceled\n"
     ]
    }
   ],
   "source": [
    "def get_available_voices():\n",
    "    \"\"\"\n",
    "    Get list of available voices from Azure Speech Service\n",
    "    \n",
    "    Returns:\n",
    "        list: List of available voices with details\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create synthesizer to get voices\n",
    "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "        \n",
    "        print(\"🎭 Fetching available voices...\")\n",
    "        \n",
    "        # Get voices\n",
    "        result = synthesizer.get_voices_async().get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.VoicesListRetrieved:\n",
    "            voices = result.voices\n",
    "            print(f\"✅ Found {len(voices)} available voices\")\n",
    "            \n",
    "            # Group voices by language\n",
    "            voices_by_language = {}\n",
    "            for voice in voices:\n",
    "                locale = voice.locale\n",
    "                if locale not in voices_by_language:\n",
    "                    voices_by_language[locale] = []\n",
    "                \n",
    "                voices_by_language[locale].append({\n",
    "                    'name': voice.name,\n",
    "                    'gender': voice.gender.name,\n",
    "                    'voice_type': voice.voice_type.name\n",
    "                })\n",
    "            \n",
    "            # Display popular languages and their voices\n",
    "            popular_languages = ['en-US', 'en-GB', 'es-ES', 'fr-FR', 'de-DE', 'it-IT', 'ja-JP', 'ko-KR', 'zh-CN']\n",
    "            \n",
    "            print(\"\\n🌍 Popular Languages and Voices:\")\n",
    "            for lang in popular_languages:\n",
    "                if lang in voices_by_language:\n",
    "                    voices = voices_by_language[lang]\n",
    "                    print(f\"\\n📍 {lang} ({len(voices)} voices):\")\n",
    "                    for voice in voices[:5]:  # Show first 5 voices\n",
    "                        print(f\"   🗣️ {voice['name']} ({voice['gender']}, {voice['voice_type']})\")\n",
    "                    if len(voices) > 5:\n",
    "                        print(f\"   ... and {len(voices) - 5} more\")\n",
    "            \n",
    "            return voices_by_language\n",
    "            \n",
    "        else:\n",
    "            print(f\"❌ Failed to retrieve voices: {result.reason}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error retrieving voices: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get and display available voices\n",
    "available_voices = get_available_voices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c5264",
   "metadata": {},
   "source": [
    "## 7. Performance Tips and Best Practices\n",
    "\n",
    "### 🔧 Optimization Techniques\n",
    "- **Batch Processing**: Process multiple audio files together\n",
    "- **Streaming**: Use streaming for real-time applications\n",
    "- **Caching**: Cache frequently used audio outputs\n",
    "- **Connection Reuse**: Reuse speech service connections\n",
    "\n",
    "### 🛡️ Security Best Practices\n",
    "- **Use Managed Identity** when possible\n",
    "- **Rotate API keys** regularly\n",
    "- **Monitor usage** and set up alerts\n",
    "- **Secure audio data** in transit and at rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccae86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚡ Running TTS Performance Test...\n",
      "⚡ Performance Testing - Text-to-Speech\n",
      "🎭 Voice: en-US-AriaNeural\n",
      "📊 Samples: 5\n",
      "\n",
      "🔄 Processing sample 1/5...\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Short text for testing.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 1.03 seconds\n",
      "\n",
      "🔄 Processing sample 2/5...\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'This is a medium length text sample that contains more words and should take a bit longer to process.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 1.03 seconds\n",
      "\n",
      "🔄 Processing sample 2/5...\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'This is a medium length text sample that contains more words and should take a bit longer to process.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 1.03 seconds\n",
      "\n",
      "🔄 Processing sample 3/5...\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'This is a much longer text sample that contains significantly more content and words, which should demonstrate how the speech synthesis performance scales with longer input text. It includes multiple sentences and various punctuation marks to test the system thoroughly.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 1.03 seconds\n",
      "\n",
      "🔄 Processing sample 3/5...\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'This is a much longer text sample that contains significantly more content and words, which should demonstrate how the speech synthesis performance scales with longer input text. It includes multiple sentences and various punctuation marks to test the system thoroughly.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 1.02 seconds\n",
      "\n",
      "🔄 Processing sample 4/5...\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Quick test!'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 1.02 seconds\n",
      "\n",
      "🔄 Processing sample 4/5...\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Quick test!'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 1.03 seconds\n",
      "\n",
      "🔄 Processing sample 5/5...\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Azure Speech Services provide powerful text-to-speech and speech-to-text capabilities.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 1.03 seconds\n",
      "\n",
      "🔄 Processing sample 5/5...\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'Azure Speech Services provide powerful text-to-speech and speech-to-text capabilities.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 0.84 seconds\n",
      "\n",
      "📊 Performance Test Results:\n",
      "   ⏱️ Total Time: 4.96 seconds\n",
      "   ✅ Successful: 0\n",
      "   ❌ Failed: 5\n",
      "   📈 Average Time/Sample: 0.00 seconds\n",
      "   🚀 Samples/Minute: 0.0\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "❌ Failed after 0.84 seconds\n",
      "\n",
      "📊 Performance Test Results:\n",
      "   ⏱️ Total Time: 4.96 seconds\n",
      "   ✅ Successful: 0\n",
      "   ❌ Failed: 5\n",
      "   📈 Average Time/Sample: 0.00 seconds\n",
      "   🚀 Samples/Minute: 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def performance_test_tts(text_samples, voice_name=\"en-US-AriaNeural\"):\n",
    "    \"\"\"\n",
    "    Test text-to-speech performance with multiple samples\n",
    "    \n",
    "    Args:\n",
    "        text_samples (list): List of text samples to test\n",
    "        voice_name (str): Voice to use for synthesis\n",
    "    \n",
    "    Returns:\n",
    "        dict: Performance metrics\n",
    "    \"\"\"\n",
    "    print(f\"⚡ Performance Testing - Text-to-Speech\")\n",
    "    print(f\"🎭 Voice: {voice_name}\")\n",
    "    print(f\"📊 Samples: {len(text_samples)}\")\n",
    "    \n",
    "    results = {\n",
    "        'total_time': 0,\n",
    "        'successful_conversions': 0,\n",
    "        'failed_conversions': 0,\n",
    "        'average_time_per_sample': 0,\n",
    "        'samples_per_minute': 0,\n",
    "        'generated_files': []\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, text in enumerate(text_samples, 1):\n",
    "        print(f\"\\n🔄 Processing sample {i}/{len(text_samples)}...\")\n",
    "        sample_start = time.time()\n",
    "        \n",
    "        output_file = f\"perf_test_{i}.wav\"\n",
    "        result_path = text_to_speech(\n",
    "            text, \n",
    "            voice_name=voice_name, \n",
    "            output_file=output_file\n",
    "        )\n",
    "        \n",
    "        sample_end = time.time()\n",
    "        sample_time = sample_end - sample_start\n",
    "        \n",
    "        if result_path:\n",
    "            results['successful_conversions'] += 1\n",
    "            results['generated_files'].append(result_path)\n",
    "            print(f\"✅ Completed in {sample_time:.2f} seconds\")\n",
    "        else:\n",
    "            results['failed_conversions'] += 1\n",
    "            print(f\"❌ Failed after {sample_time:.2f} seconds\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    results['total_time'] = end_time - start_time\n",
    "    \n",
    "    if results['successful_conversions'] > 0:\n",
    "        results['average_time_per_sample'] = results['total_time'] / results['successful_conversions']\n",
    "        results['samples_per_minute'] = 60 / results['average_time_per_sample']\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n📊 Performance Test Results:\")\n",
    "    print(f\"   ⏱️ Total Time: {results['total_time']:.2f} seconds\")\n",
    "    print(f\"   ✅ Successful: {results['successful_conversions']}\")\n",
    "    print(f\"   ❌ Failed: {results['failed_conversions']}\")\n",
    "    print(f\"   📈 Average Time/Sample: {results['average_time_per_sample']:.2f} seconds\")\n",
    "    print(f\"   🚀 Samples/Minute: {results['samples_per_minute']:.1f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Performance test samples\n",
    "perf_test_samples = [\n",
    "    \"Short text for testing.\",\n",
    "    \"This is a medium length text sample that contains more words and should take a bit longer to process.\",\n",
    "    \"This is a much longer text sample that contains significantly more content and words, which should demonstrate how the speech synthesis performance scales with longer input text. It includes multiple sentences and various punctuation marks to test the system thoroughly.\",\n",
    "    \"Quick test!\",\n",
    "    \"Azure Speech Services provide powerful text-to-speech and speech-to-text capabilities.\"\n",
    "]\n",
    "\n",
    "# Run performance test\n",
    "print(\"\\n⚡ Running TTS Performance Test...\")\n",
    "perf_results = performance_test_tts(perf_test_samples)\n",
    "\n",
    "# Show generated files\n",
    "if perf_results['generated_files']:\n",
    "    print(f\"\\n📁 Generated Files:\")\n",
    "    for file_path in perf_results['generated_files']:\n",
    "        file_size = Path(file_path).stat().st_size\n",
    "        print(f\"   🎵 {Path(file_path).name} ({file_size:,} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29ada4",
   "metadata": {},
   "source": [
    "## 8. Troubleshooting and Common Issues\n",
    "\n",
    "### 🔧 Common Problems and Solutions\n",
    "\n",
    "1. **Authentication Issues**\n",
    "   - ❌ Error: \"Invalid subscription key\"\n",
    "   - ✅ Solution: Check your API key and region settings\n",
    "\n",
    "2. **Audio Issues**\n",
    "   - ❌ Error: \"No microphone detected\"\n",
    "   - ✅ Solution: Check microphone permissions and hardware\n",
    "\n",
    "3. **Rate Limiting**\n",
    "   - ❌ Error: \"Too many requests\"\n",
    "   - ✅ Solution: Implement retry logic with exponential backoff\n",
    "\n",
    "4. **Language Support**\n",
    "   - ❌ Error: \"Language not supported\"\n",
    "   - ✅ Solution: Check available languages and update configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196b5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Running Azure Speech Service Diagnostics...\n",
      "============================================================\n",
      "\n",
      "1️⃣ Configuration Check:\n",
      "   ✅ API Key: Configured\n",
      "   ✅ Region: eastus\n",
      "\n",
      "2️⃣ Service Connectivity:\n",
      "   ❌ Connection: Failed (ResultReason.Canceled)\n",
      "\n",
      "3️⃣ Basic Text-to-Speech Test:\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'This is a diagnostic test.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "   ❌ Connection: Failed (ResultReason.Canceled)\n",
      "\n",
      "3️⃣ Basic Text-to-Speech Test:\n",
      "🎵 Converting text to speech...\n",
      "📝 Text: 'This is a diagnostic test.'\n",
      "🗣️ Voice: en-US-AriaNeural\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "   ❌ TTS: Not working\n",
      "\n",
      "4️⃣ Audio File Processing Test:\n",
      "❌ Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: Sending. Received audio size: 0 bytes.\n",
      "   ❌ TTS: Not working\n",
      "\n",
      "4️⃣ Audio File Processing Test:\n",
      "❌ Error processing audio file: Exception with error code: \n",
      "[CALL STACK BEGIN]\n",
      "\n",
      "    > pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - recognizer_create_speech_recognizer_from_config\n",
      "    - recognizer_create_speech_recognizer_from_config\n",
      "\n",
      "[CALL STACK END]\n",
      "\n",
      "Exception with an error code: 0x9 (SPXERR_UNEXPECTED_EOF)\n",
      "   ❌ STT: Not working\n",
      "\n",
      "============================================================\n",
      "🏁 Diagnostics completed!\n",
      "❌ Error processing audio file: Exception with error code: \n",
      "[CALL STACK BEGIN]\n",
      "\n",
      "    > pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - pal_string_to_wstring\n",
      "    - recognizer_create_speech_recognizer_from_config\n",
      "    - recognizer_create_speech_recognizer_from_config\n",
      "\n",
      "[CALL STACK END]\n",
      "\n",
      "Exception with an error code: 0x9 (SPXERR_UNEXPECTED_EOF)\n",
      "   ❌ STT: Not working\n",
      "\n",
      "============================================================\n",
      "🏁 Diagnostics completed!\n"
     ]
    }
   ],
   "source": [
    "def run_diagnostics():\n",
    "    \"\"\"\n",
    "    Run diagnostic tests for Azure Speech Service setup\n",
    "    \"\"\"\n",
    "    print(\"🔧 Running Azure Speech Service Diagnostics...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test 1: Configuration Check\n",
    "    print(\"\\n1️⃣ Configuration Check:\")\n",
    "    if 'speech_key' in globals() and speech_key and speech_key != \"your-speech-key-here\":\n",
    "        print(\"   ✅ API Key: Configured\")\n",
    "    else:\n",
    "        print(\"   ❌ API Key: Not configured\")\n",
    "    \n",
    "    if 'speech_region' in globals() and speech_region:\n",
    "        print(f\"   ✅ Region: {speech_region}\")\n",
    "    else:\n",
    "        print(\"   ❌ Region: Not configured\")\n",
    "    \n",
    "    # Test 2: Output Directory\n",
    "    print(\"\\n2️⃣ Output Directory Check:\")\n",
    "    if output_dir.exists():\n",
    "        print(f\"   ✅ Output Directory: {output_dir.absolute()}\")\n",
    "        files_count = len(list(output_dir.glob('*.wav')))\n",
    "        print(f\"   📁 Audio files in directory: {files_count}\")\n",
    "    else:\n",
    "        print(f\"   ❌ Output Directory: Not found\")\n",
    "    \n",
    "    # Test 3: Service Connectivity\n",
    "    print(\"\\n3️⃣ Service Connectivity:\")\n",
    "    try:\n",
    "        if 'speech_config' in globals():\n",
    "            # Try to get voices (this tests connectivity)\n",
    "            synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "            result = synthesizer.get_voices_async().get()\n",
    "            if result.reason == speechsdk.ResultReason.VoicesListRetrieved:\n",
    "                print(f\"   ✅ Connection: Success ({len(result.voices)} voices available)\")\n",
    "            else:\n",
    "                print(f\"   ❌ Connection: Failed ({result.reason})\")\n",
    "        else:\n",
    "            print(\"   ❌ Connection: Speech config not available\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Connection: Error - {e}\")\n",
    "    \n",
    "    # Test 4: Basic TTS Test\n",
    "    print(\"\\n4️⃣ Basic Text-to-Speech Test:\")\n",
    "    test_file = \"diagnostic_test.wav\"\n",
    "    result_path = text_to_speech(\n",
    "        \"This is a diagnostic test.\", \n",
    "        output_file=test_file\n",
    "    )\n",
    "    if result_path:\n",
    "        print(\"   ✅ TTS: Working correctly\")\n",
    "        file_size = Path(result_path).stat().st_size\n",
    "        print(f\"   📁 File size: {file_size:,} bytes\")\n",
    "    else:\n",
    "        print(\"   ❌ TTS: Not working\")\n",
    "    \n",
    "    # Test 5: Audio File Processing\n",
    "    print(\"\\n5️⃣ Audio File Processing Test:\")\n",
    "    if result_path and Path(result_path).exists():\n",
    "        stt_result = speech_to_text_from_file(test_file)\n",
    "        if stt_result:\n",
    "            print(\"   ✅ STT: Working correctly\")\n",
    "            print(f\"   📝 Recognized: '{stt_result}'\")\n",
    "        else:\n",
    "            print(\"   ❌ STT: Not working\")\n",
    "    else:\n",
    "        print(\"   ❌ Audio file not found for STT test\")\n",
    "    \n",
    "    # Test 6: File Listing\n",
    "    print(\"\\n6️⃣ Generated Files Summary:\")\n",
    "    audio_files = list(output_dir.glob('*.wav'))\n",
    "    if audio_files:\n",
    "        print(f\"   📊 Total audio files: {len(audio_files)}\")\n",
    "        total_size = sum(f.stat().st_size for f in audio_files)\n",
    "        print(f\"   💾 Total size: {total_size:,} bytes ({total_size/1024/1024:.1f} MB)\")\n",
    "        print(\"   📁 Recent files:\")\n",
    "        for file in sorted(audio_files, key=lambda x: x.stat().st_mtime)[-5:]:\n",
    "            print(f\"      🎵 {file.name}\")\n",
    "    else:\n",
    "        print(\"   📁 No audio files found\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🏁 Diagnostics completed!\")\n",
    "\n",
    "# Run diagnostics\n",
    "run_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41c663",
   "metadata": {},
   "source": [
    "## 9. Interactive Demo\n",
    "\n",
    "Try these interactive features with your own content!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡 Customize the variables above and uncomment the code to test!\n",
      "🎤 Available features:\n",
      "   • Text-to-Speech with different voices\n",
      "   • SSML for advanced speech control\n",
      "   • Speech-to-Text from microphone\n",
      "   • Speech translation between languages\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Interactive Speech Demo\n",
    "# Customize these variables and run the cell!\n",
    "\n",
    "# Text-to-Speech Demo\n",
    "your_text = \"Replace this with your own text to convert to speech!\"\n",
    "your_voice = \"en-US-AriaNeural\"  # Try: en-GB-SoniaNeural, es-ES-ElviraNeural, fr-FR-DeniseNeural\n",
    "\n",
    "# Uncomment to test your text\n",
    "# print(\"🎵 Converting your text to speech...\")\n",
    "# result = text_to_speech(your_text, voice_name=your_voice, output_file=\"your_speech.wav\")\n",
    "# if result:\n",
    "#     print(f\"✅ Your audio saved to: {result}\")\n",
    "\n",
    "# SSML Demo\n",
    "your_ssml = '''\n",
    "<speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"en-US\">\n",
    "    <voice name=\"en-US-AriaNeural\">\n",
    "        Welcome to <emphasis level=\"strong\">Azure Speech Services</emphasis>!\n",
    "        <break time=\"1s\"/>\n",
    "        <prosody rate=\"slow\">This is amazing technology.</prosody>\n",
    "    </voice>\n",
    "</speak>\n",
    "'''\n",
    "\n",
    "# Uncomment to test your SSML\n",
    "# print(\"\\n🎭 Converting your SSML to speech...\")\n",
    "# result = ssml_to_speech(your_ssml, output_file=\"your_ssml_speech.wav\")\n",
    "# if result:\n",
    "#     print(f\"✅ Your SSML audio saved to: {result}\")\n",
    "\n",
    "print(\"💡 Customize the variables above and uncomment the code to test!\")\n",
    "print(\"🎤 Available features:\")\n",
    "print(\"   • Text-to-Speech with different voices\")\n",
    "print(\"   • SSML for advanced speech control\")\n",
    "print(\"   • Speech-to-Text from microphone\")\n",
    "print(\"   • Speech translation between languages\")\n",
    "print(f\"\\n📁 All audio files will be saved to: {output_dir.absolute()}\")\n",
    "\n",
    "# Show current audio files\n",
    "audio_files = list(output_dir.glob('*.wav'))\n",
    "if audio_files:\n",
    "    print(f\"\\n🎵 Current audio files ({len(audio_files)}):\")\n",
    "    for file in sorted(audio_files)[-10:]:  # Show last 10 files\n",
    "        file_size = file.stat().st_size\n",
    "        print(f\"   🎶 {file.name} ({file_size:,} bytes)\")\n",
    "else:\n",
    "    print(\"\\n📁 No audio files generated yet. Run the examples above to create some!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892ad29",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Next Steps\n",
    "\n",
    "🎉 **Congratulations!** You've successfully explored Azure AI Speech Services capabilities including:\n",
    "- ✅ Text-to-Speech with neural voices\n",
    "- ✅ Speech-to-Text recognition\n",
    "- ✅ SSML for advanced speech control\n",
    "- ✅ Speech translation\n",
    "- ✅ Performance optimization\n",
    "- ✅ Diagnostic tools\n",
    "\n",
    "### 🚀 Next Steps\n",
    "1. **Explore other notebooks** in this series:\n",
    "   - Azure AI Language Services ✅\n",
    "   - Azure AI Vision Services ➡️\n",
    "   - Azure AI Document Intelligence ➡️\n",
    "\n",
    "2. **Build real applications** using Speech Services:\n",
    "   - Voice assistants and chatbots\n",
    "   - Accessibility tools for visually impaired\n",
    "   - Language learning applications\n",
    "   - Real-time transcription services\n",
    "   - Multi-language customer support\n",
    "\n",
    "3. **Advanced features to explore**:\n",
    "   - Custom Neural Voice creation\n",
    "   - Speaker Recognition and Verification\n",
    "   - Conversation Transcription\n",
    "   - Pronunciation Assessment\n",
    "   - Audio Content Creation\n",
    "\n",
    "### 📚 Additional Resources\n",
    "- [Azure Speech Service Documentation](https://docs.microsoft.com/azure/cognitive-services/speech-service/)\n",
    "- [Speech SDK Samples](https://github.com/Azure-Samples/cognitive-services-speech-sdk)\n",
    "- [Voice Gallery](https://speech.microsoft.com/portal/voicegallery)\n",
    "- [SSML Reference](https://docs.microsoft.com/azure/cognitive-services/speech-service/speech-synthesis-markup)\n",
    "- [Speech Service Pricing](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/)\n",
    "\n",
    "### 🔗 Useful Links\n",
    "- [Speech Studio Portal](https://speech.microsoft.com/portal) - Test and customize speech models\n",
    "- [Language Support](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support) - Complete language list\n",
    "- [Voice Samples](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support#neural-voices) - Listen to voice samples\n",
    "\n",
    "**Happy coding with Azure Speech Services! 🎤🎵**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
