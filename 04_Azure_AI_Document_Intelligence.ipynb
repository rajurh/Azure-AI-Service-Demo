{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50fce16",
   "metadata": {},
   "source": [
    "# Azure AI Document Intelligence Demo\n",
    "\n",
    "This notebook demonstrates the capabilities of Azure AI Document Intelligence (formerly Form Recognizer) including:\n",
    "- **Prebuilt Models**: Extract data from invoices, receipts, business cards, and ID documents\n",
    "- **Layout Analysis**: Analyze document structure, tables, and text regions\n",
    "- **Custom Models**: Train models for specific document types\n",
    "- **Document Classification**: Classify documents into different categories\n",
    "- **Key-Value Pair Extraction**: Extract structured data from forms\n",
    "- **Table Extraction**: Extract tables and their contents\n",
    "\n",
    "## Prerequisites\n",
    "- Azure subscription\n",
    "- Azure Document Intelligence resource created in Azure portal\n",
    "- Python 3.8 or higher\n",
    "- Sample documents for testing (PDFs, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d59a3a",
   "metadata": {},
   "source": [
    "## 1. Setup and Package Installation\n",
    "\n",
    "First, let's install the required Azure Document Intelligence SDK and supporting packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required Azure Document Intelligence SDK and supporting packages\n",
    "!pip install azure-ai-formrecognizer azure-identity python-dotenv\n",
    "!pip install pillow matplotlib requests numpy pandas\n",
    "!pip install tabulate  # For nice table formatting\n",
    "\n",
    "# For document processing and visualization\n",
    "!pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "# Azure Document Intelligence imports\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üìÑ Ready to analyze documents with Azure AI Document Intelligence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12b49dc",
   "metadata": {},
   "source": [
    "## 2. Azure Document Intelligence Configuration\n",
    "\n",
    "### Option 1: Using Environment Variables (Recommended)\n",
    "Set these environment variables in your system or create a `.env` file:\n",
    "```\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/\n",
    "AZURE_DOCUMENT_INTELLIGENCE_KEY=your-api-key\n",
    "```\n",
    "\n",
    "### Option 2: Using Managed Identity (For Azure-hosted applications)\n",
    "When running on Azure services with managed identity enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c853e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Azure Document Intelligence Service\n",
    "document_endpoint = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT') or \"https://your-resource.cognitiveservices.azure.com/\"\n",
    "document_key = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_KEY') or \"your-document-key-here\"\n",
    "\n",
    "# Create Document Intelligence client\n",
    "if document_key and document_key != \"your-document-key-here\":\n",
    "    credential = AzureKeyCredential(document_key)\n",
    "    document_client = DocumentAnalysisClient(endpoint=document_endpoint, credential=credential)\n",
    "    print(f\"‚úÖ Document Intelligence client created successfully!\")\n",
    "    print(f\"üîó Endpoint: {document_endpoint}\")\n",
    "else:\n",
    "    print(\"‚ùå Please set AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT and AZURE_DOCUMENT_INTELLIGENCE_KEY environment variables\")\n",
    "    print(\"You can get these from your Azure Document Intelligence resource in the Azure portal\")\n",
    "\n",
    "# Helper function to load and display documents\n",
    "def load_and_display_document(document_path_or_url, title=\"Document\", figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Load and display a document image from local path or URL\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if document_path_or_url.startswith('http'):\n",
    "            response = requests.get(document_path_or_url)\n",
    "            image = Image.open(io.BytesIO(response.content))\n",
    "        else:\n",
    "            image = Image.open(document_path_or_url)\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(image)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading document: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ef4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample documents for testing\n",
    "import urllib.request\n",
    "\n",
    "sample_documents = {\n",
    "    \"invoice.pdf\": \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/sample-invoice.pdf\",\n",
    "    \"receipt.jpg\": \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/contoso-allinone.jpg\",\n",
    "    \"business_card.jpg\": \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/business-card-english.jpg\",\n",
    "    \"id_document.jpg\": \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/DriverLicense.png\",\n",
    "    \"layout_document.jpg\": \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/sample-layout.jpg\"\n",
    "}\n",
    "\n",
    "def download_sample_documents():\n",
    "    \"\"\"Download sample documents for testing\"\"\"\n",
    "    print(\"üì• Downloading sample documents...\")\n",
    "    \n",
    "    # Create documents directory if it doesn't exist\n",
    "    os.makedirs(\"sample_documents\", exist_ok=True)\n",
    "    \n",
    "    for filename, url in sample_documents.items():\n",
    "        filepath = os.path.join(\"sample_documents\", filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, filepath)\n",
    "                print(f\"‚úÖ Downloaded: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to download {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"üìÅ Already exists: {filename}\")\n",
    "    \n",
    "    print(\"üéØ Sample documents ready for analysis!\")\n",
    "\n",
    "# Download sample documents\n",
    "download_sample_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b49106",
   "metadata": {},
   "source": [
    "## 3. Prebuilt Models - Invoice Analysis\n",
    "\n",
    "Azure Document Intelligence provides prebuilt models for common document types:\n",
    "- **Invoices**: Extract vendor details, amounts, dates, line items\n",
    "- **Receipts**: Extract merchant info, transaction details, items\n",
    "- **Business Cards**: Extract contact information\n",
    "- **ID Documents**: Extract personal information from IDs and passports\n",
    "- **W-2 Forms**: Extract tax information\n",
    "- **Health Insurance Cards**: Extract insurance details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_invoice(document_path_or_url):\n",
    "    \"\"\"\n",
    "    Analyze invoice using prebuilt invoice model\n",
    "    \n",
    "    Args:\n",
    "        document_path_or_url (str): Path to local document or URL\n",
    "    \n",
    "    Returns:\n",
    "        dict: Extracted invoice data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üìä Analyzing invoice: {document_path_or_url}\")\n",
    "        \n",
    "        # Display the document\n",
    "        if not document_path_or_url.endswith('.pdf'):\n",
    "            doc_image = load_and_display_document(document_path_or_url, \"Invoice for Analysis\")\n",
    "        else:\n",
    "            print(\"üìÑ PDF document loaded for analysis\")\n",
    "        \n",
    "        # Analyze document using prebuilt invoice model\n",
    "        if document_path_or_url.startswith('http'):\n",
    "            poller = document_client.begin_analyze_document_from_url(\"prebuilt-invoice\", document_path_or_url)\n",
    "        else:\n",
    "            with open(document_path_or_url, 'rb') as document:\n",
    "                poller = document_client.begin_analyze_document(\"prebuilt-invoice\", document)\n",
    "        \n",
    "        result = poller.result()\n",
    "        \n",
    "        # Extract and display invoice information\n",
    "        invoice_data = {}\n",
    "        \n",
    "        print(\"\\nüìã INVOICE ANALYSIS RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for document in result.documents:\n",
    "            print(f\"\\nüìÑ Document type: {document.doc_type}\")\n",
    "            print(f\"üìä Confidence: {document.confidence:.2f}\")\n",
    "            \n",
    "            # Extract key fields\n",
    "            fields_to_extract = [\n",
    "                'VendorName', 'VendorAddress', 'CustomerName', 'CustomerAddress',\n",
    "                'InvoiceId', 'InvoiceDate', 'DueDate', 'InvoiceTotal',\n",
    "                'AmountDue', 'SubTotal', 'TotalTax'\n",
    "            ]\n",
    "            \n",
    "            print(\"\\nüè¢ VENDOR & CUSTOMER INFO:\")\n",
    "            for field_name in ['VendorName', 'VendorAddress', 'CustomerName', 'CustomerAddress']:\n",
    "                if field_name in document.fields:\n",
    "                    field = document.fields[field_name]\n",
    "                    if field.value:\n",
    "                        print(f\"   üìù {field_name}: {field.value}\")\n",
    "                        invoice_data[field_name] = field.value\n",
    "            \n",
    "            print(\"\\nüìÖ INVOICE DETAILS:\")\n",
    "            for field_name in ['InvoiceId', 'InvoiceDate', 'DueDate']:\n",
    "                if field_name in document.fields:\n",
    "                    field = document.fields[field_name]\n",
    "                    if field.value:\n",
    "                        print(f\"   üìã {field_name}: {field.value}\")\n",
    "                        invoice_data[field_name] = field.value\n",
    "            \n",
    "            print(\"\\nüí∞ FINANCIAL DETAILS:\")\n",
    "            for field_name in ['SubTotal', 'TotalTax', 'InvoiceTotal', 'AmountDue']:\n",
    "                if field_name in document.fields:\n",
    "                    field = document.fields[field_name]\n",
    "                    if field.value:\n",
    "                        print(f\"   üíµ {field_name}: {field.value}\")\n",
    "                        invoice_data[field_name] = field.value\n",
    "            \n",
    "            # Extract line items\n",
    "            if 'Items' in document.fields:\n",
    "                items_field = document.fields['Items']\n",
    "                if items_field.value:\n",
    "                    print(\"\\nüõí LINE ITEMS:\")\n",
    "                    items_data = []\n",
    "                    \n",
    "                    for i, item in enumerate(items_field.value):\n",
    "                        item_dict = {}\n",
    "                        print(f\"\\n   Item {i+1}:\")\n",
    "                        \n",
    "                        if item.value:\n",
    "                            for name, field in item.value.items():\n",
    "                                if field.value:\n",
    "                                    print(f\"      {name}: {field.value}\")\n",
    "                                    item_dict[name] = field.value\n",
    "                        \n",
    "                        items_data.append(item_dict)\n",
    "                    \n",
    "                    invoice_data['Items'] = items_data\n",
    "                    \n",
    "                    # Create items table\n",
    "                    if items_data:\n",
    "                        print(\"\\nüìä ITEMS SUMMARY TABLE:\")\n",
    "                        df_items = pd.DataFrame(items_data)\n",
    "                        print(tabulate(df_items, headers='keys', tablefmt='grid', showindex=False))\n",
    "        \n",
    "        return invoice_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing invoice: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test invoice analysis\n",
    "invoice_path = os.path.join(\"sample_documents\", \"invoice.pdf\")\n",
    "if os.path.exists(invoice_path):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä INVOICE ANALYSIS DEMO\")\n",
    "    print(\"=\"*80)\n",
    "    invoice_results = analyze_invoice(invoice_path)\n",
    "else:\n",
    "    print(\"‚ùå Sample invoice not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963095f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_receipt(document_path_or_url):\n",
    "    \"\"\"\n",
    "    Analyze receipt using prebuilt receipt model\n",
    "    \n",
    "    Args:\n",
    "        document_path_or_url (str): Path to local document or URL\n",
    "    \n",
    "    Returns:\n",
    "        dict: Extracted receipt data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üßæ Analyzing receipt: {document_path_or_url}\")\n",
    "        \n",
    "        # Display the document\n",
    "        doc_image = load_and_display_document(document_path_or_url, \"Receipt for Analysis\")\n",
    "        if not doc_image:\n",
    "            return None\n",
    "        \n",
    "        # Analyze document using prebuilt receipt model\n",
    "        if document_path_or_url.startswith('http'):\n",
    "            poller = document_client.begin_analyze_document_from_url(\"prebuilt-receipt\", document_path_or_url)\n",
    "        else:\n",
    "            with open(document_path_or_url, 'rb') as document:\n",
    "                poller = document_client.begin_analyze_document(\"prebuilt-receipt\", document)\n",
    "        \n",
    "        result = poller.result()\n",
    "        \n",
    "        # Extract and display receipt information\n",
    "        receipt_data = {}\n",
    "        \n",
    "        print(\"\\nüßæ RECEIPT ANALYSIS RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for document in result.documents:\n",
    "            print(f\"\\nüìÑ Document type: {document.doc_type}\")\n",
    "            print(f\"üìä Confidence: {document.confidence:.2f}\")\n",
    "            \n",
    "            print(\"\\nüè™ MERCHANT INFO:\")\n",
    "            merchant_fields = ['MerchantName', 'MerchantAddress', 'MerchantPhoneNumber']\n",
    "            for field_name in merchant_fields:\n",
    "                if field_name in document.fields:\n",
    "                    field = document.fields[field_name]\n",
    "                    if field.value:\n",
    "                        print(f\"   üè¢ {field_name}: {field.value}\")\n",
    "                        receipt_data[field_name] = field.value\n",
    "            \n",
    "            print(\"\\nüìÖ TRANSACTION INFO:\")\n",
    "            transaction_fields = ['TransactionDate', 'TransactionTime']\n",
    "            for field_name in transaction_fields:\n",
    "                if field_name in document.fields:\n",
    "                    field = document.fields[field_name]\n",
    "                    if field.value:\n",
    "                        print(f\"   üìã {field_name}: {field.value}\")\n",
    "                        receipt_data[field_name] = field.value\n",
    "            \n",
    "            print(\"\\nüí∞ FINANCIAL DETAILS:\")\n",
    "            financial_fields = ['Subtotal', 'Tax', 'Total']\n",
    "            for field_name in financial_fields:\n",
    "                if field_name in document.fields:\n",
    "                    field = document.fields[field_name]\n",
    "                    if field.value:\n",
    "                        print(f\"   üíµ {field_name}: {field.value}\")\n",
    "                        receipt_data[field_name] = field.value\n",
    "            \n",
    "            # Extract receipt items\n",
    "            if 'Items' in document.fields:\n",
    "                items_field = document.fields['Items']\n",
    "                if items_field.value:\n",
    "                    print(\"\\nüõí PURCHASED ITEMS:\")\n",
    "                    items_data = []\n",
    "                    \n",
    "                    for i, item in enumerate(items_field.value):\n",
    "                        item_dict = {}\n",
    "                        print(f\"\\n   Item {i+1}:\")\n",
    "                        \n",
    "                        if item.value:\n",
    "                            for name, field in item.value.items():\n",
    "                                if field.value:\n",
    "                                    print(f\"      {name}: {field.value}\")\n",
    "                                    item_dict[name] = field.value\n",
    "                        \n",
    "                        items_data.append(item_dict)\n",
    "                    \n",
    "                    receipt_data['Items'] = items_data\n",
    "                    \n",
    "                    # Create items table\n",
    "                    if items_data:\n",
    "                        print(\"\\nüìä ITEMS SUMMARY TABLE:\")\n",
    "                        df_items = pd.DataFrame(items_data)\n",
    "                        print(tabulate(df_items, headers='keys', tablefmt='grid', showindex=False))\n",
    "        \n",
    "        return receipt_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing receipt: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test receipt analysis\n",
    "receipt_path = os.path.join(\"sample_documents\", \"receipt.jpg\")\n",
    "if os.path.exists(receipt_path):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üßæ RECEIPT ANALYSIS DEMO\")\n",
    "    print(\"=\"*80)\n",
    "    receipt_results = analyze_receipt(receipt_path)\n",
    "else:\n",
    "    print(\"‚ùå Sample receipt not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2dc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_business_card(document_path_or_url):\n",
    "    \"\"\"\n",
    "    Analyze business card using prebuilt business card model\n",
    "    \n",
    "    Args:\n",
    "        document_path_or_url (str): Path to local document or URL\n",
    "    \n",
    "    Returns:\n",
    "        dict: Extracted business card data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üíº Analyzing business card: {document_path_or_url}\")\n",
    "        \n",
    "        # Display the document\n",
    "        doc_image = load_and_display_document(document_path_or_url, \"Business Card for Analysis\")\n",
    "        if not doc_image:\n",
    "            return None\n",
    "        \n",
    "        # Analyze document using prebuilt business card model\n",
    "        if document_path_or_url.startswith('http'):\n",
    "            poller = document_client.begin_analyze_document_from_url(\"prebuilt-businessCard\", document_path_or_url)\n",
    "        else:\n",
    "            with open(document_path_or_url, 'rb') as document:\n",
    "                poller = document_client.begin_analyze_document(\"prebuilt-businessCard\", document)\n",
    "        \n",
    "        result = poller.result()\n",
    "        \n",
    "        # Extract and display business card information\n",
    "        card_data = {}\n",
    "        \n",
    "        print(\"\\nüíº BUSINESS CARD ANALYSIS RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for document in result.documents:\n",
    "            print(f\"\\nüìÑ Document type: {document.doc_type}\")\n",
    "            print(f\"üìä Confidence: {document.confidence:.2f}\")\n",
    "            \n",
    "            print(\"\\nüë§ CONTACT INFORMATION:\")\n",
    "            \n",
    "            # Extract contact fields\n",
    "            contact_fields = {\n",
    "                'ContactNames': 'üë§ Name',\n",
    "                'JobTitles': 'üíº Job Title',\n",
    "                'Departments': 'üè¢ Department',\n",
    "                'CompanyNames': 'üè¢ Company',\n",
    "                'Addresses': 'üìç Address',\n",
    "                'MobilePhones': 'üì± Mobile Phone',\n",
    "                'WorkPhones': '‚òéÔ∏è Work Phone',\n",
    "                'Faxes': 'üì† Fax',\n",
    "                'Emails': 'üìß Email',\n",
    "                'Websites': 'üåê Website'\n",
    "            }\n",
    "            \n",
    "            for field_name, display_name in contact_fields.items():\n",
    "                if field_name in document.fields:\n",
    "                    field = document.fields[field_name]\n",
    "                    if field.value:\n",
    "                        if isinstance(field.value, list):\n",
    "                            for item in field.value:\n",
    "                                if item.value:\n",
    "                                    print(f\"   {display_name}: {item.value}\")\n",
    "                                    if field_name not in card_data:\n",
    "                                        card_data[field_name] = []\n",
    "                                    card_data[field_name].append(item.value)\n",
    "                        else:\n",
    "                            print(f\"   {display_name}: {field.value}\")\n",
    "                            card_data[field_name] = field.value\n",
    "        \n",
    "        # Create a summary table\n",
    "        if card_data:\n",
    "            print(\"\\nüìä CONTACT SUMMARY:\")\n",
    "            summary_data = []\n",
    "            for field_name, value in card_data.items():\n",
    "                if isinstance(value, list):\n",
    "                    for item in value:\n",
    "                        summary_data.append([field_name.replace('s', ''), item])\n",
    "                else:\n",
    "                    summary_data.append([field_name.replace('s', ''), value])\n",
    "            \n",
    "            print(tabulate(summary_data, headers=['Field', 'Value'], tablefmt='grid'))\n",
    "        \n",
    "        return card_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing business card: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test business card analysis\n",
    "card_path = os.path.join(\"sample_documents\", \"business_card.jpg\")\n",
    "if os.path.exists(card_path):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üíº BUSINESS CARD ANALYSIS DEMO\")\n",
    "    print(\"=\"*80)\n",
    "    card_results = analyze_business_card(card_path)\n",
    "else:\n",
    "    print(\"‚ùå Sample business card not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4919a",
   "metadata": {},
   "source": [
    "## 4. Layout Analysis\n",
    "\n",
    "Layout analysis extracts text, tables, and structural information from documents without using a specific prebuilt model. This is useful for:\n",
    "- **General document processing**: Any document type\n",
    "- **Table extraction**: Structured data from tables\n",
    "- **Reading order**: Logical reading sequence\n",
    "- **Document structure**: Headers, paragraphs, lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcbd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document_layout(document_path_or_url):\n",
    "    \"\"\"\n",
    "    Analyze document layout and structure\n",
    "    \n",
    "    Args:\n",
    "        document_path_or_url (str): Path to local document or URL\n",
    "    \n",
    "    Returns:\n",
    "        dict: Layout analysis results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üìã Analyzing document layout: {document_path_or_url}\")\n",
    "        \n",
    "        # Display the document\n",
    "        if not document_path_or_url.endswith('.pdf'):\n",
    "            doc_image = load_and_display_document(document_path_or_url, \"Document for Layout Analysis\")\n",
    "        else:\n",
    "            print(\"üìÑ PDF document loaded for layout analysis\")\n",
    "        \n",
    "        # Analyze document using layout model\n",
    "        if document_path_or_url.startswith('http'):\n",
    "            poller = document_client.begin_analyze_document_from_url(\"prebuilt-layout\", document_path_or_url)\n",
    "        else:\n",
    "            with open(document_path_or_url, 'rb') as document:\n",
    "                poller = document_client.begin_analyze_document(\"prebuilt-layout\", document)\n",
    "        \n",
    "        result = poller.result()\n",
    "        \n",
    "        # Extract layout information\n",
    "        layout_data = {\n",
    "            'pages': [],\n",
    "            'tables': [],\n",
    "            'paragraphs': [],\n",
    "            'lines': []\n",
    "        }\n",
    "        \n",
    "        print(\"\\nüìã LAYOUT ANALYSIS RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Pages information\n",
    "        print(f\"\\nüìÑ DOCUMENT PAGES: {len(result.pages)}\")\n",
    "        for page_idx, page in enumerate(result.pages):\n",
    "            page_info = {\n",
    "                'page_number': page_idx + 1,\n",
    "                'width': page.width,\n",
    "                'height': page.height,\n",
    "                'angle': page.angle,\n",
    "                'lines_count': len(page.lines)\n",
    "            }\n",
    "            layout_data['pages'].append(page_info)\n",
    "            print(f\"   üìÑ Page {page_idx + 1}: {page.width}x{page.height}, {len(page.lines)} lines\")\n",
    "        \n",
    "        # Tables information\n",
    "        if result.tables:\n",
    "            print(f\"\\nüìä TABLES FOUND: {len(result.tables)}\")\n",
    "            for table_idx, table in enumerate(result.tables):\n",
    "                table_info = {\n",
    "                    'table_number': table_idx + 1,\n",
    "                    'row_count': table.row_count,\n",
    "                    'column_count': table.column_count,\n",
    "                    'cells': []\n",
    "                }\n",
    "                \n",
    "                print(f\"\\n   üìä Table {table_idx + 1}: {table.row_count} rows √ó {table.column_count} columns\")\n",
    "                \n",
    "                # Extract table data\n",
    "                table_matrix = [[\"\" for _ in range(table.column_count)] for _ in range(table.row_count)]\n",
    "                \n",
    "                for cell in table.cells:\n",
    "                    if cell.row_index < table.row_count and cell.column_index < table.column_count:\n",
    "                        table_matrix[cell.row_index][cell.column_index] = cell.content\n",
    "                        table_info['cells'].append({\n",
    "                            'row': cell.row_index,\n",
    "                            'column': cell.column_index,\n",
    "                            'content': cell.content,\n",
    "                            'kind': cell.kind if hasattr(cell, 'kind') else 'content'\n",
    "                        })\n",
    "                \n",
    "                # Display table\n",
    "                print(f\"\\n      Table {table_idx + 1} Content:\")\n",
    "                print(tabulate(table_matrix, tablefmt='grid'))\n",
    "                \n",
    "                layout_data['tables'].append(table_info)\n",
    "        \n",
    "        # Paragraphs information\n",
    "        if hasattr(result, 'paragraphs') and result.paragraphs:\n",
    "            print(f\"\\nüìù PARAGRAPHS FOUND: {len(result.paragraphs)}\")\n",
    "            for para_idx, paragraph in enumerate(result.paragraphs[:5]):  # Show first 5 paragraphs\n",
    "                para_info = {\n",
    "                    'paragraph_number': para_idx + 1,\n",
    "                    'content': paragraph.content,\n",
    "                    'role': paragraph.role if hasattr(paragraph, 'role') else 'paragraph'\n",
    "                }\n",
    "                layout_data['paragraphs'].append(para_info)\n",
    "                print(f\"   üìù Paragraph {para_idx + 1}: {paragraph.content[:100]}...\")\n",
    "                if hasattr(paragraph, 'role') and paragraph.role:\n",
    "                    print(f\"      Role: {paragraph.role}\")\n",
    "        \n",
    "        # Text content\n",
    "        print(f\"\\nüìÑ EXTRACTED TEXT (first 500 characters):\")\n",
    "        if result.content:\n",
    "            print(f\"'{result.content[:500]}...\")\n",
    "            layout_data['full_text'] = result.content\n",
    "        \n",
    "        return layout_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing layout: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test layout analysis\n",
    "layout_doc_path = os.path.join(\"sample_documents\", \"layout_document.jpg\")\n",
    "if os.path.exists(layout_doc_path):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìã DOCUMENT LAYOUT ANALYSIS DEMO\")\n",
    "    print(\"=\"*80)\n",
    "    layout_results = analyze_document_layout(layout_doc_path)\n",
    "else:\n",
    "    # Try with invoice if layout document not available\n",
    "    invoice_path = os.path.join(\"sample_documents\", \"invoice.pdf\")\n",
    "    if os.path.exists(invoice_path):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìã DOCUMENT LAYOUT ANALYSIS DEMO (using invoice)\")\n",
    "        print(\"=\"*80)\n",
    "        layout_results = analyze_document_layout(invoice_path)\n",
    "    else:\n",
    "        print(\"‚ùå No sample documents found for layout analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_id_document(document_path_or_url):\n",
    "    \"\"\"\n",
    "    Analyze ID document using prebuilt ID document model\n",
    "    \n",
    "    Args:\n",
    "        document_path_or_url (str): Path to local document or URL\n",
    "    \n",
    "    Returns:\n",
    "        dict: Extracted ID document data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üÜî Analyzing ID document: {document_path_or_url}\")\n",
    "        \n",
    "        # Display the document\n",
    "        doc_image = load_and_display_document(document_path_or_url, \"ID Document for Analysis\")\n",
    "        if not doc_image:\n",
    "            return None\n",
    "        \n",
    "        # Analyze document using prebuilt ID document model\n",
    "        if document_path_or_url.startswith('http'):\n",
    "            poller = document_client.begin_analyze_document_from_url(\"prebuilt-idDocument\", document_path_or_url)\n",
    "        else:\n",
    "            with open(document_path_or_url, 'rb') as document:\n",
    "                poller = document_client.begin_analyze_document(\"prebuilt-idDocument\", document)\n",
    "        \n",
    "        result = poller.result()\n",
    "        \n",
    "        # Extract and display ID document information\n",
    "        id_data = {}\n",
    "        \n",
    "        print(\"\\nüÜî ID DOCUMENT ANALYSIS RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for document in result.documents:\n",
    "            print(f\"\\nüìÑ Document type: {document.doc_type}\")\n",
    "            print(f\"üìä Confidence: {document.confidence:.2f}\")\n",
    "            \n",
    "            print(\"\\nüë§ PERSONAL INFORMATION:\")\n",
    "            \n",
    "            # Extract ID fields\n",
    "            id_fields = {\n",
    "                'FirstName': 'üë§ First Name',\n",
    "                'LastName': 'üë§ Last Name',\n",
    "                'DocumentNumber': 'üÜî Document Number',\n",
    "                'DateOfBirth': 'üìÖ Date of Birth',\n",
    "                'DateOfExpiration': 'üìÖ Expiration Date',\n",
    "                'Sex': '‚öß Sex',\n",
    "                'Address': 'üìç Address',\n",
    "                'CountryRegion': 'üåç Country/Region',\n",
    "                'Region': 'üìç State/Region'\n",
    "            }\n",
    "            \n",
    "            for field_name, display_name in id_fields.items():\n",
    "                if field_name in document.fields:\n",
    "                    field = document.fields[field_name]\n",
    "                    if field.value:\n",
    "                        print(f\"   {display_name}: {field.value}\")\n",
    "                        id_data[field_name] = field.value\n",
    "        \n",
    "        # Create a summary table\n",
    "        if id_data:\n",
    "            print(\"\\nüìä ID DOCUMENT SUMMARY:\")\n",
    "            summary_data = [[field_name, value] for field_name, value in id_data.items()]\n",
    "            print(tabulate(summary_data, headers=['Field', 'Value'], tablefmt='grid'))\n",
    "        \n",
    "        return id_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing ID document: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test ID document analysis\n",
    "id_doc_path = os.path.join(\"sample_documents\", \"id_document.jpg\")\n",
    "if os.path.exists(id_doc_path):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üÜî ID DOCUMENT ANALYSIS DEMO\")\n",
    "    print(\"=\"*80)\n",
    "    id_results = analyze_id_document(id_doc_path)\n",
    "else:\n",
    "    print(\"‚ùå Sample ID document not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a29d7",
   "metadata": {},
   "source": [
    "## 5. General Document Analysis\n",
    "\n",
    "General document analysis can process any document type and extract:\n",
    "- **Text content**: All readable text\n",
    "- **Key-value pairs**: Form fields and their values\n",
    "- **Tables**: Structured tabular data\n",
    "- **Selection marks**: Checkboxes and radio buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_general_document(document_path_or_url):\n",
    "    \"\"\"\n",
    "    Perform general document analysis\n",
    "    \n",
    "    Args:\n",
    "        document_path_or_url (str): Path to local document or URL\n",
    "    \n",
    "    Returns:\n",
    "        dict: General analysis results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üìÑ Performing general document analysis: {document_path_or_url}\")\n",
    "        \n",
    "        # Display the document\n",
    "        if not document_path_or_url.endswith('.pdf'):\n",
    "            doc_image = load_and_display_document(document_path_or_url, \"Document for General Analysis\")\n",
    "        else:\n",
    "            print(\"üìÑ PDF document loaded for general analysis\")\n",
    "        \n",
    "        # Analyze document using general document model\n",
    "        if document_path_or_url.startswith('http'):\n",
    "            poller = document_client.begin_analyze_document_from_url(\"prebuilt-document\", document_path_or_url)\n",
    "        else:\n",
    "            with open(document_path_or_url, 'rb') as document:\n",
    "                poller = document_client.begin_analyze_document(\"prebuilt-document\", document)\n",
    "        \n",
    "        result = poller.result()\n",
    "        \n",
    "        # Extract general document information\n",
    "        doc_data = {\n",
    "            'key_value_pairs': [],\n",
    "            'tables': [],\n",
    "            'text_content': '',\n",
    "            'selection_marks': []\n",
    "        }\n",
    "        \n",
    "        print(\"\\nüìÑ GENERAL DOCUMENT ANALYSIS RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Key-value pairs\n",
    "        if result.key_value_pairs:\n",
    "            print(f\"\\nüîë KEY-VALUE PAIRS FOUND: {len(result.key_value_pairs)}\")\n",
    "            for kv_idx, kv_pair in enumerate(result.key_value_pairs[:10]):  # Show first 10\n",
    "                key_text = kv_pair.key.content if kv_pair.key else \"No key\"\n",
    "                value_text = kv_pair.value.content if kv_pair.value else \"No value\"\n",
    "                \n",
    "                kv_data = {\n",
    "                    'key': key_text,\n",
    "                    'value': value_text\n",
    "                }\n",
    "                doc_data['key_value_pairs'].append(kv_data)\n",
    "                \n",
    "                print(f\"   üîë {key_text}: {value_text}\")\n",
    "        \n",
    "        # Tables (reuse from layout analysis)\n",
    "        if result.tables:\n",
    "            print(f\"\\nüìä TABLES FOUND: {len(result.tables)}\")\n",
    "            for table_idx, table in enumerate(result.tables[:3]):  # Show first 3 tables\n",
    "                print(f\"\\n   üìä Table {table_idx + 1}: {table.row_count} rows √ó {table.column_count} columns\")\n",
    "                \n",
    "                # Extract table data\n",
    "                table_matrix = [[\"\" for _ in range(table.column_count)] for _ in range(table.row_count)]\n",
    "                \n",
    "                for cell in table.cells:\n",
    "                    if cell.row_index < table.row_count and cell.column_index < table.column_count:\n",
    "                        table_matrix[cell.row_index][cell.column_index] = cell.content\n",
    "                \n",
    "                # Display table\n",
    "                print(f\"\\n      Table {table_idx + 1} Content:\")\n",
    "                print(tabulate(table_matrix, tablefmt='grid'))\n",
    "                \n",
    "                doc_data['tables'].append({\n",
    "                    'table_number': table_idx + 1,\n",
    "                    'row_count': table.row_count,\n",
    "                    'column_count': table.column_count,\n",
    "                    'data': table_matrix\n",
    "                })\n",
    "        \n",
    "        # Text content\n",
    "        if result.content:\n",
    "            doc_data['text_content'] = result.content\n",
    "            print(f\"\\nüìÑ EXTRACTED TEXT (first 300 characters):\")\n",
    "            print(f\"'{result.content[:300]}...'\")\n",
    "        \n",
    "        # Selection marks (checkboxes, radio buttons)\n",
    "        if hasattr(result, 'pages'):\n",
    "            selection_marks_count = 0\n",
    "            for page in result.pages:\n",
    "                if hasattr(page, 'selection_marks'):\n",
    "                    for mark in page.selection_marks:\n",
    "                        selection_marks_count += 1\n",
    "                        doc_data['selection_marks'].append({\n",
    "                            'state': mark.state,\n",
    "                            'confidence': mark.confidence\n",
    "                        })\n",
    "            \n",
    "            if selection_marks_count > 0:\n",
    "                print(f\"\\n‚òëÔ∏è SELECTION MARKS FOUND: {selection_marks_count}\")\n",
    "                selected_count = len([m for m in doc_data['selection_marks'] if m['state'] == 'selected'])\n",
    "                unselected_count = len([m for m in doc_data['selection_marks'] if m['state'] == 'unselected'])\n",
    "                print(f\"   ‚úÖ Selected: {selected_count}\")\n",
    "                print(f\"   ‚¨ú Unselected: {unselected_count}\")\n",
    "        \n",
    "        return doc_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in general document analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test general document analysis with available documents\n",
    "test_documents = [\"invoice.pdf\", \"receipt.jpg\", \"business_card.jpg\"]\n",
    "\n",
    "for doc_name in test_documents:\n",
    "    doc_path = os.path.join(\"sample_documents\", doc_name)\n",
    "    if os.path.exists(doc_path):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"üìÑ GENERAL DOCUMENT ANALYSIS: {doc_name}\")\n",
    "        print(\"=\"*80)\n",
    "        general_results = analyze_general_document(doc_path)\n",
    "        break\n",
    "else:\n",
    "    print(\"‚ùå No sample documents found for general analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d98c30",
   "metadata": {},
   "source": [
    "## 6. Batch Document Processing\n",
    "\n",
    "Process multiple documents efficiently with batch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ade660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_analyze_documents(document_paths, model_type=\"prebuilt-document\"):\n",
    "    \"\"\"\n",
    "    Analyze multiple documents in batch\n",
    "    \n",
    "    Args:\n",
    "        document_paths (list): List of document paths\n",
    "        model_type (str): Type of model to use\n",
    "    \n",
    "    Returns:\n",
    "        list: Analysis results for all documents\n",
    "    \"\"\"\n",
    "    print(f\"üìä Batch processing {len(document_paths)} documents with {model_type} model...\")\n",
    "    \n",
    "    results = []\n",
    "    model_functions = {\n",
    "        \"prebuilt-invoice\": \"Invoice\",\n",
    "        \"prebuilt-receipt\": \"Receipt\", \n",
    "        \"prebuilt-businessCard\": \"Business Card\",\n",
    "        \"prebuilt-idDocument\": \"ID Document\",\n",
    "        \"prebuilt-layout\": \"Layout\",\n",
    "        \"prebuilt-document\": \"General Document\"\n",
    "    }\n",
    "    \n",
    "    for i, doc_path in enumerate(document_paths, 1):\n",
    "        try:\n",
    "            print(f\"\\nüîÑ Processing document {i}/{len(document_paths)}: {os.path.basename(doc_path)}\")\n",
    "            \n",
    "            # Analyze document\n",
    "            with open(doc_path, 'rb') as document:\n",
    "                poller = document_client.begin_analyze_document(model_type, document)\n",
    "            \n",
    "            result = poller.result()\n",
    "            \n",
    "            # Extract basic information\n",
    "            doc_result = {\n",
    "                'document': os.path.basename(doc_path),\n",
    "                'model_type': model_type,\n",
    "                'success': True,\n",
    "                'pages_count': len(result.pages) if result.pages else 0,\n",
    "                'tables_count': len(result.tables) if result.tables else 0,\n",
    "                'content_length': len(result.content) if result.content else 0\n",
    "            }\n",
    "            \n",
    "            # Extract model-specific information\n",
    "            if result.documents:\n",
    "                doc_result['documents_found'] = len(result.documents)\n",
    "                doc_result['document_types'] = [doc.doc_type for doc in result.documents]\n",
    "                doc_result['confidence_scores'] = [doc.confidence for doc in result.documents]\n",
    "            \n",
    "            print(f\"   ‚úÖ Success: {doc_result['pages_count']} pages, {doc_result['tables_count']} tables\")\n",
    "            \n",
    "            results.append(doc_result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error processing {doc_path}: {e}\")\n",
    "            results.append({\n",
    "                'document': os.path.basename(doc_path),\n",
    "                'model_type': model_type,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nüìà BATCH PROCESSING SUMMARY:\")\n",
    "    successful = len([r for r in results if r['success']])\n",
    "    failed = len([r for r in results if not r['success']])\n",
    "    print(f\"   ‚úÖ Successful: {successful}\")\n",
    "    print(f\"   ‚ùå Failed: {failed}\")\n",
    "    \n",
    "    # Create summary table\n",
    "    if results:\n",
    "        print(f\"\\nüìä RESULTS SUMMARY:\")\n",
    "        summary_data = []\n",
    "        for result in results:\n",
    "            if result['success']:\n",
    "                summary_data.append([\n",
    "                    result['document'],\n",
    "                    result['model_type'],\n",
    "                    result['pages_count'],\n",
    "                    result['tables_count'],\n",
    "                    result['content_length']\n",
    "                ])\n",
    "            else:\n",
    "                summary_data.append([\n",
    "                    result['document'],\n",
    "                    result['model_type'],\n",
    "                    \"Error\",\n",
    "                    \"Error\", \n",
    "                    \"Error\"\n",
    "                ])\n",
    "        \n",
    "        headers = ['Document', 'Model', 'Pages', 'Tables', 'Content Length']\n",
    "        print(tabulate(summary_data, headers=headers, tablefmt='grid'))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test batch processing with available documents\n",
    "available_docs = []\n",
    "for doc_name in sample_documents.keys():\n",
    "    doc_path = os.path.join(\"sample_documents\", doc_name)\n",
    "    if os.path.exists(doc_path):\n",
    "        available_docs.append(doc_path)\n",
    "\n",
    "if available_docs:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä BATCH DOCUMENT PROCESSING DEMO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Test batch processing with general document model\n",
    "    batch_results = batch_analyze_documents(available_docs, \"prebuilt-document\")\n",
    "else:\n",
    "    print(\"‚ùå No sample documents available for batch processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575469a7",
   "metadata": {},
   "source": [
    "## 7. Performance Monitoring and Optimization\n",
    "\n",
    "### ‚ö° Performance Tips\n",
    "- **Document optimization**: Ensure good quality scans\n",
    "- **File size management**: Optimize large documents\n",
    "- **Batch operations**: Process multiple documents together\n",
    "- **Model selection**: Choose the right prebuilt model\n",
    "- **Error handling**: Implement retry logic for failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f873e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def performance_test_document_intelligence(document_paths, model_type=\"prebuilt-document\"):\n",
    "    \"\"\"\n",
    "    Test Document Intelligence API performance\n",
    "    \n",
    "    Args:\n",
    "        document_paths (list): List of document paths to test\n",
    "        model_type (str): Type of model to test\n",
    "    \n",
    "    Returns:\n",
    "        dict: Performance metrics\n",
    "    \"\"\"\n",
    "    print(f\"‚ö° Performance Testing - {model_type} Analysis\")\n",
    "    print(f\"üìä Testing with {len(document_paths)} documents\")\n",
    "    \n",
    "    results = {\n",
    "        'total_time': 0,\n",
    "        'successful_operations': 0,\n",
    "        'failed_operations': 0,\n",
    "        'average_time_per_document': 0,\n",
    "        'documents_per_minute': 0,\n",
    "        'start_time': datetime.now(),\n",
    "        'model_type': model_type\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, doc_path in enumerate(document_paths, 1):\n",
    "        print(f\"\\nüîÑ Processing document {i}/{len(document_paths)}...\")\n",
    "        doc_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            with open(doc_path, 'rb') as document:\n",
    "                poller = document_client.begin_analyze_document(model_type, document)\n",
    "            \n",
    "            result = poller.result()\n",
    "            \n",
    "            doc_end = time.time()\n",
    "            doc_time = doc_end - doc_start\n",
    "            \n",
    "            # Check if analysis was successful\n",
    "            success = result and (result.content or result.tables or result.pages)\n",
    "            \n",
    "            if success:\n",
    "                results['successful_operations'] += 1\n",
    "                print(f\"   ‚úÖ Completed in {doc_time:.2f} seconds\")\n",
    "                if result.pages:\n",
    "                    print(f\"      üìÑ Pages: {len(result.pages)}\")\n",
    "                if result.tables:\n",
    "                    print(f\"      üìä Tables: {len(result.tables)}\")\n",
    "                if result.content:\n",
    "                    print(f\"      üìù Text length: {len(result.content)} characters\")\n",
    "            else:\n",
    "                results['failed_operations'] += 1\n",
    "                print(f\"   ‚ùå Failed after {doc_time:.2f} seconds\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            results['failed_operations'] += 1\n",
    "            doc_time = time.time() - doc_start\n",
    "            print(f\"   ‚ùå Error after {doc_time:.2f} seconds: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    results['total_time'] = end_time - start_time\n",
    "    results['end_time'] = datetime.now()\n",
    "    \n",
    "    if results['successful_operations'] > 0:\n",
    "        results['average_time_per_document'] = results['total_time'] / results['successful_operations']\n",
    "        results['documents_per_minute'] = 60 / results['average_time_per_document']\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nüìä Performance Test Results:\")\n",
    "    print(f\"   ‚è±Ô∏è Total Time: {results['total_time']:.2f} seconds\")\n",
    "    print(f\"   ‚úÖ Successful: {results['successful_operations']}\")\n",
    "    print(f\"   ‚ùå Failed: {results['failed_operations']}\")\n",
    "    print(f\"   üìà Average Time/Document: {results['average_time_per_document']:.2f} seconds\")\n",
    "    print(f\"   üöÄ Documents/Minute: {results['documents_per_minute']:.1f}\")\n",
    "    print(f\"   üìÖ Test Duration: {results['start_time'].strftime('%H:%M:%S')} - {results['end_time'].strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run performance tests if documents are available\n",
    "if available_docs and len(available_docs) >= 2:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö° DOCUMENT INTELLIGENCE PERFORMANCE TESTING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Test with different models\n",
    "    models_to_test = [\"prebuilt-document\", \"prebuilt-layout\"]\n",
    "    \n",
    "    for model in models_to_test:\n",
    "        print(f\"\\nüß™ Testing {model} model:\")\n",
    "        perf_results = performance_test_document_intelligence(available_docs[:3], model)\n",
    "else:\n",
    "    print(\"\\nüí° Not enough sample documents for performance testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd475fac",
   "metadata": {},
   "source": [
    "## 8. Interactive Demo\n",
    "\n",
    "Try Document Intelligence features with your own documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ee8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Interactive Document Intelligence Demo\n",
    "# Customize these variables and run the cell!\n",
    "\n",
    "# Option 1: Use a URL to a document\n",
    "your_document_url = \"https://example.com/your-document.pdf\"  # Replace with your document URL\n",
    "\n",
    "# Option 2: Use a local document path\n",
    "your_local_document = \"path/to/your/document.pdf\"  # Replace with your local document path\n",
    "\n",
    "# Choose analysis type\n",
    "analysis_models = {\n",
    "    'invoice': 'prebuilt-invoice - Extract invoice data',\n",
    "    'receipt': 'prebuilt-receipt - Extract receipt data', \n",
    "    'business_card': 'prebuilt-businessCard - Extract contact info',\n",
    "    'id_document': 'prebuilt-idDocument - Extract ID information',\n",
    "    'layout': 'prebuilt-layout - Extract structure and tables',\n",
    "    'general': 'prebuilt-document - General document analysis'\n",
    "}\n",
    "\n",
    "selected_model = 'general'  # Change this to test different models\n",
    "\n",
    "def interactive_document_analysis(document_source, model_type='general'):\n",
    "    \"\"\"\n",
    "    Interactive analysis function for testing\n",
    "    \"\"\"\n",
    "    model_mapping = {\n",
    "        'invoice': 'prebuilt-invoice',\n",
    "        'receipt': 'prebuilt-receipt',\n",
    "        'business_card': 'prebuilt-businessCard',\n",
    "        'id_document': 'prebuilt-idDocument', \n",
    "        'layout': 'prebuilt-layout',\n",
    "        'general': 'prebuilt-document'\n",
    "    }\n",
    "    \n",
    "    actual_model = model_mapping.get(model_type, 'prebuilt-document')\n",
    "    print(f\"üéØ Running {actual_model} analysis on your document...\")\n",
    "    \n",
    "    try:\n",
    "        if document_source.startswith('http'):\n",
    "            poller = document_client.begin_analyze_document_from_url(actual_model, document_source)\n",
    "        else:\n",
    "            with open(document_source, 'rb') as document:\n",
    "                poller = document_client.begin_analyze_document(actual_model, document)\n",
    "        \n",
    "        result = poller.result()\n",
    "        \n",
    "        # Basic results\n",
    "        print(f\"\\nüìä Analysis completed successfully!\")\n",
    "        print(f\"   üìÑ Pages: {len(result.pages) if result.pages else 0}\")\n",
    "        print(f\"   üìä Tables: {len(result.tables) if result.tables else 0}\")\n",
    "        print(f\"   üìù Text length: {len(result.content) if result.content else 0} characters\")\n",
    "        \n",
    "        if result.documents:\n",
    "            print(f\"   üìã Documents found: {len(result.documents)}\")\n",
    "            for doc in result.documents:\n",
    "                print(f\"      Type: {doc.doc_type}, Confidence: {doc.confidence:.2f}\")\n",
    "        \n",
    "        # Show first 200 characters of text\n",
    "        if result.content:\n",
    "            print(f\"\\nüìÑ Text preview: '{result.content[:200]}...'\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Instructions for use\n",
    "print(\"üéØ INTERACTIVE DOCUMENT INTELLIGENCE DEMO\")\n",
    "print(\"=\" * 50)\n",
    "print(\"To use this demo:\")\n",
    "print(\"1. Replace 'your_document_url' or 'your_local_document' with your document\")\n",
    "print(\"2. Choose your analysis model from:\")\n",
    "for key, description in analysis_models.items():\n",
    "    print(f\"   ‚Ä¢ {key}: {description}\")\n",
    "print(\"3. Set 'selected_model' variable\")\n",
    "print(\"4. Uncomment the analysis code below\")\n",
    "print(\"\\nüí° Available models:\", list(analysis_models.keys()))\n",
    "\n",
    "# Test with sample documents if available\n",
    "if available_docs:\n",
    "    print(f\"\\nüîß Testing with sample document: {os.path.basename(available_docs[0])}\")\n",
    "    # Uncomment to test with first available sample document\n",
    "    # sample_result = interactive_document_analysis(available_docs[0], selected_model)\n",
    "\n",
    "# Uncomment the lines below to test with your document\n",
    "# if your_document_url != \"https://example.com/your-document.pdf\":\n",
    "#     result = interactive_document_analysis(your_document_url, selected_model)\n",
    "# elif os.path.exists(your_local_document):\n",
    "#     result = interactive_document_analysis(your_local_document, selected_model)\n",
    "# else:\n",
    "#     print(\"‚ùå Please provide a valid document URL or local path\")\n",
    "\n",
    "print(\"\\nüöÄ Ready to analyze your documents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e0ede",
   "metadata": {},
   "source": [
    "## 9. Troubleshooting and Best Practices\n",
    "\n",
    "### üîß Common Issues and Solutions\n",
    "\n",
    "1. **Authentication Errors**\n",
    "   - ‚ùå \"Access denied\" or \"Invalid subscription key\"\n",
    "   - ‚úÖ Check your Document Intelligence key and endpoint\n",
    "   - ‚úÖ Verify the resource is in the correct region\n",
    "\n",
    "2. **Document Format Issues**\n",
    "   - ‚ùå \"Unsupported file format\"\n",
    "   - ‚úÖ Supported formats: PDF, JPEG, PNG, BMP, TIFF\n",
    "   - ‚úÖ Maximum file size: 500 MB for paid tier, 4 MB for free tier\n",
    "   - ‚úÖ PDF: Maximum 2000 pages\n",
    "\n",
    "3. **Quality Issues**\n",
    "   - ‚ùå Poor extraction accuracy\n",
    "   - ‚úÖ Ensure good scan quality and resolution\n",
    "   - ‚úÖ Avoid skewed or rotated documents\n",
    "   - ‚úÖ Use appropriate lighting and contrast\n",
    "\n",
    "4. **Model Selection**\n",
    "   - ‚ùå Wrong model for document type\n",
    "   - ‚úÖ Use prebuilt models when available\n",
    "   - ‚úÖ Fall back to layout/general models for unknown types\n",
    "   - ‚úÖ Consider custom models for specialized documents\n",
    "\n",
    "### üí° Best Practices\n",
    "\n",
    "- **Document Quality**: Use high-resolution, well-lit scans\n",
    "- **Model Selection**: Choose the most specific prebuilt model\n",
    "- **Error Handling**: Always implement try-catch blocks\n",
    "- **Caching**: Cache results for frequently processed documents\n",
    "- **Monitoring**: Track API usage and costs\n",
    "- **Security**: Use managed identity in production\n",
    "- **Preprocessing**: Optimize document quality before processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e19ebd",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Next Steps\n",
    "\n",
    "üéâ **Congratulations!** You've successfully explored Azure AI Document Intelligence capabilities including:\n",
    "- ‚úÖ Prebuilt models (Invoice, Receipt, Business Card, ID Document)\n",
    "- ‚úÖ Layout analysis and table extraction\n",
    "- ‚úÖ General document processing\n",
    "- ‚úÖ Key-value pair extraction\n",
    "- ‚úÖ Batch processing\n",
    "- ‚úÖ Performance optimization\n",
    "\n",
    "### üöÄ Next Steps\n",
    "1. **Complete Azure AI Series** - You've finished all notebooks:\n",
    "   - ‚úÖ Azure AI Language Services\n",
    "   - ‚úÖ Azure AI Speech Services\n",
    "   - ‚úÖ Azure AI Vision Services\n",
    "   - ‚úÖ Azure AI Document Intelligence\n",
    "\n",
    "2. **Build real applications** using Document Intelligence:\n",
    "   - Invoice processing automation\n",
    "   - Receipt digitization systems\n",
    "   - Business card management\n",
    "   - Document workflow automation\n",
    "   - Compliance and audit systems\n",
    "\n",
    "3. **Advanced features to explore**:\n",
    "   - Custom model training\n",
    "   - Document classification\n",
    "   - Composed models\n",
    "   - REST API integration\n",
    "   - Azure Logic Apps integration\n",
    "\n",
    "### üìö Additional Resources\n",
    "- [Azure Document Intelligence Documentation](https://docs.microsoft.com/azure/applied-ai-services/form-recognizer/)\n",
    "- [Document Intelligence SDK Samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/formrecognizer)\n",
    "- [Document Intelligence Studio](https://formrecognizer.appliedai.azure.com/) - Test and train models\n",
    "- [Pricing Information](https://azure.microsoft.com/pricing/details/form-recognizer/)\n",
    "\n",
    "### üîó Useful Links\n",
    "- [Supported File Formats](https://docs.microsoft.com/azure/applied-ai-services/form-recognizer/concept-model-overview)\n",
    "- [Prebuilt Models Overview](https://docs.microsoft.com/azure/applied-ai-services/form-recognizer/concept-model-overview#prebuilt-models)\n",
    "- [Custom Model Training](https://docs.microsoft.com/azure/applied-ai-services/form-recognizer/concept-custom)\n",
    "- [API Reference](https://docs.microsoft.com/rest/api/formrecognizer/)\n",
    "- [SDK Reference](https://docs.microsoft.com/python/api/azure-ai-formrecognizer/)\n",
    "\n",
    "**Happy document processing with Azure AI Document Intelligence! üìÑü§ñ**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Azure AI Services Demo Series Complete!\n",
    "\n",
    "You have now completed the full Azure AI Services demo series. These notebooks provide a comprehensive foundation for building intelligent applications using:\n",
    "\n",
    "- üó£Ô∏è **Language Services**: Text analytics and natural language processing\n",
    "- üé§ **Speech Services**: Speech-to-text, text-to-speech, and translation\n",
    "- üëÅÔ∏è **Vision Services**: Image analysis, OCR, and object detection\n",
    "- üìÑ **Document Intelligence**: Structured data extraction from documents\n",
    "\n",
    "Start building amazing AI-powered applications! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
